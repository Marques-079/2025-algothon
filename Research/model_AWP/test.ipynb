{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWP_pipeline.py\n",
    "# Builds features CSV and provides streaming warmup + inference pipeline\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import accuracy_score\n",
    "from precision_labeller import plot_all_regimes_long\n",
    "from AWP_inference import load_model, predict_regimes\n",
    "\n",
    "# ── Part A: Offline feature construction ─────────────────────────────────────\n",
    "def compute_slope_vol(prices: pd.Series, slope_win: int, vol_win: int) -> pd.DataFrame:\n",
    "    logp = np.log(prices)\n",
    "    t = np.arange(slope_win)\n",
    "    X = np.vstack([t, np.ones_like(t)]).T\n",
    "\n",
    "    def slope_of_window(y):\n",
    "        m, _ = np.linalg.lstsq(X, y, rcond=None)[0]\n",
    "        return m\n",
    "\n",
    "    slope = (\n",
    "        logp.rolling(window=slope_win, min_periods=slope_win)\n",
    "            .apply(slope_of_window, raw=True)\n",
    "    )\n",
    "    rtn = logp.diff()\n",
    "    vol = rtn.rolling(window=vol_win, min_periods=vol_win).std()\n",
    "    return pd.DataFrame({\"slope\": slope, \"vol\": vol})\n",
    "\n",
    "\n",
    "def build_feature_matrix(\n",
    "    price_file: str,\n",
    "    drop_last: int = 10,\n",
    "    output_csv: str = \"features_all_models4.csv\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Builds a CSV of features + autolabelled regimes for all instruments.\n",
    "    \"\"\"\n",
    "    df_raw = pd.read_csv(price_file, sep=r\"\\s+\", header=None)\n",
    "    n_rows, n_cols = df_raw.shape\n",
    "    all_rows = []\n",
    "\n",
    "    for inst in range(n_cols):\n",
    "        close = df_raw.iloc[:, inst]\n",
    "        T = len(close)\n",
    "        true_regs = plot_all_regimes_long(end_point=T, plot_graph=False, inst=inst)\n",
    "        true_regs = pd.Series(true_regs[:T - drop_last], name=\"true_regime\")\n",
    "\n",
    "        feats = pd.DataFrame(index=true_regs.index)\n",
    "        logp = np.log(close)\n",
    "\n",
    "        # MA regime\n",
    "        ma_s = logp.rolling(window=5, min_periods=1).mean()\n",
    "        ma_l = logp.rolling(window=70, min_periods=1).mean()\n",
    "        feats[\"ma_reg\"] = np.where(ma_l > ma_s, 0, 2)[:T - drop_last]\n",
    "\n",
    "        # EMA regime\n",
    "        ema_s = logp.ewm(span=5, adjust=False).mean()\n",
    "        ema_l = logp.ewm(span=50, adjust=False).mean()\n",
    "        feats[\"ema_reg\"] = np.where(ema_s > ema_l, 2, 0)[:T - drop_last]\n",
    "\n",
    "        # Slope/Vol regime\n",
    "        sv = compute_slope_vol(close, slope_win=30, vol_win=100).dropna()\n",
    "        idx = sv.index[sv.index < T - drop_last]\n",
    "        median_vol = sv.loc[idx, \"vol\"].median()\n",
    "        feats.loc[idx, \"slope_vol_reg\"] = np.where(\n",
    "            (sv.loc[idx, \"slope\"] > 0) & (sv.loc[idx, \"vol\"] < median_vol), 2, 0\n",
    "        )\n",
    "\n",
    "        # ... (other feature routines) ...\n",
    "\n",
    "        feats[\"true_regime\"] = true_regs\n",
    "        feats[\"inst\"] = inst\n",
    "        feats[\"time\"] = feats.index\n",
    "        all_rows.append(feats.reset_index(drop=True))\n",
    "\n",
    "    final_df = pd.concat(all_rows, ignore_index=True)\n",
    "    final_df.to_csv(output_csv, index=False)\n",
    "    print(f\"✅ Features written to: {output_csv}\")\n",
    "\n",
    "\n",
    "# ── Part B: Streaming warmup + efficient inference pipeline ─────────────────────────\n",
    "class StreamingRegimePredictor:\n",
    "    \"\"\"\n",
    "    Stream in price data for multiple instruments, warm up caches,\n",
    "    and emit a 1D numpy array of regime predictions (one per instrument)\n",
    "    once both price (100) and feature (20) caches are full.  Until then,\n",
    "    returns an array filled with -999.\n",
    "    \"\"\"\n",
    "    def __init__(self, checkpoint_name: str, features_csv: str):\n",
    "        # load frozen LSTM tagger\n",
    "        self.model, self.device = load_model(checkpoint_name)\n",
    "        # load static features (post-100 warm-up) for all instruments\n",
    "        df = pd.read_csv(features_csv)\n",
    "        df = df.groupby(\"inst\", group_keys=False).apply(lambda g: g).reset_index(drop=True)\n",
    "        # pivot into array shape (n_inst, seq_len, D)\n",
    "        feat_cols = [c for c in df.columns if c not in (\"inst\",\"time\",\"true_regime\")]\n",
    "        grouped = df.groupby(\"inst\")\n",
    "        self.static_feats = np.stack([grouped.get_group(i)[feat_cols].values\n",
    "                                      for i in sorted(grouped.groups)])\n",
    "        # cache placeholders\n",
    "        self.price_cache = None     # shape: (n_inst, 100)\n",
    "        self.feature_cache = None   # shape: (n_inst, 20, D)\n",
    "        self.n_inst, self.seq_len, self.D = self.static_feats.shape\n",
    "\n",
    "    def step(self, price_matrix: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Ingest the full historical price_matrix of shape (n_inst, T).\n",
    "        If T < 120, returns array([-999]). Once T >= 120:\n",
    "         - initialize or roll price_cache to keep last 100 prices\n",
    "         - initialize or roll feature_cache to keep last 20 feature rows\n",
    "         - after updating feature_cache, run inference on each instrument\n",
    "\n",
    "        Returns:\n",
    "          preds: np.ndarray of shape (n_inst,) of current regime labels,\n",
    "                 or np.full((n_inst,), -999) if not warmed up.\n",
    "        \"\"\"\n",
    "        if price_matrix.ndim != 2:\n",
    "            raise ValueError(\"price_matrix must be 2D: (n_inst, T)\")\n",
    "        n_inst, T = price_matrix.shape\n",
    "        # not enough history\n",
    "        if T < 120:\n",
    "            return np.full((n_inst,), -999, dtype=int)\n",
    "        # initialize or update price cache\n",
    "        last_prices = price_matrix[:, -100:]\n",
    "        if self.price_cache is None:\n",
    "            self.price_cache = last_prices.copy()\n",
    "        else:\n",
    "            # roll then append\n",
    "            self.price_cache = np.roll(self.price_cache, -1, axis=1)\n",
    "            self.price_cache[:, -1] = last_prices[:, -1]\n",
    "        # determine static feature index for this new timestep\n",
    "        static_idx = T - 100 - 1  # zero-based index into static_feats axis1\n",
    "        if not (0 <= static_idx < self.seq_len):\n",
    "            # out of bounds static features\n",
    "            return np.full((n_inst,), -999, dtype=int)\n",
    "        # get new feature row for all instruments\n",
    "        new_feat = self.static_feats[:, static_idx, :]  # (n_inst, D)\n",
    "        # initialize or update feature cache\n",
    "        if self.feature_cache is None:\n",
    "            # first fill: take the first 20 rows of static_feats\n",
    "            self.feature_cache = self.static_feats[:, :20, :].copy()\n",
    "        else:\n",
    "            self.feature_cache = np.roll(self.feature_cache, -1, axis=1)\n",
    "            self.feature_cache[:, -1, :] = new_feat\n",
    "        # now caches are warm: run inference\n",
    "        preds = np.zeros(self.n_inst, dtype=int)\n",
    "        for i in range(self.n_inst):\n",
    "            feats_i = self.feature_cache[i]  # shape (20, D)\n",
    "            preds[i] = predict_regimes(self.model, self.device, feats_i)\n",
    "        return preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWP_pipeline.py\n",
    "# Builds features CSV and provides streaming warmup + inference pipeline\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import accuracy_score\n",
    "from precision_labeller import plot_all_regimes_long\n",
    "from AWP_inference import load_model, predict_regimes\n",
    "\n",
    "# ── Part A: Offline feature construction ─────────────────────────────────────\n",
    "def compute_slope_vol(prices: pd.Series, slope_win: int, vol_win: int) -> pd.DataFrame:\n",
    "    logp = np.log(prices)\n",
    "    t = np.arange(slope_win)\n",
    "    X = np.vstack([t, np.ones_like(t)]).T\n",
    "\n",
    "    def slope_of_window(y):\n",
    "        m, _ = np.linalg.lstsq(X, y, rcond=None)[0]\n",
    "        return m\n",
    "\n",
    "    slope = (\n",
    "        logp.rolling(window=slope_win, min_periods=slope_win)\n",
    "            .apply(slope_of_window, raw=True)\n",
    "    )\n",
    "    rtn = logp.diff()\n",
    "    vol = rtn.rolling(window=vol_win, min_periods=vol_win).std()\n",
    "    return pd.DataFrame({\"slope\": slope, \"vol\": vol})\n",
    "\n",
    "\n",
    "def build_feature_matrix(\n",
    "    price_file: str,\n",
    "    drop_last: int = 10,\n",
    "    output_csv: str = \"features_all_models4.csv\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Builds a CSV of features + autolabelled regimes for all instruments.\n",
    "    \"\"\"\n",
    "    df_raw = pd.read_csv(price_file, sep=r\"\\s+\", header=None)\n",
    "    n_rows, n_cols = df_raw.shape\n",
    "    all_rows = []\n",
    "\n",
    "    for inst in range(n_cols):\n",
    "        close = df_raw.iloc[:, inst]\n",
    "        T = len(close)\n",
    "        true_regs = plot_all_regimes_long(end_point=T, plot_graph=False, inst=inst)\n",
    "        true_regs = pd.Series(true_regs[:T - drop_last], name=\"true_regime\")\n",
    "\n",
    "        feats = pd.DataFrame(index=true_regs.index)\n",
    "        logp = np.log(close)\n",
    "\n",
    "        # MA regime\n",
    "        ma_s = logp.rolling(window=5, min_periods=1).mean()\n",
    "        ma_l = logp.rolling(window=70, min_periods=1).mean()\n",
    "        feats[\"ma_reg\"] = np.where(ma_l > ma_s, 0, 2)[:T - drop_last]\n",
    "\n",
    "        # EMA regime\n",
    "        ema_s = logp.ewm(span=5, adjust=False).mean()\n",
    "        ema_l = logp.ewm(span=50, adjust=False).mean()\n",
    "        feats[\"ema_reg\"] = np.where(ema_s > ema_l, 2, 0)[:T - drop_last]\n",
    "\n",
    "        # Slope/Vol regime\n",
    "        sv = compute_slope_vol(close, slope_win=30, vol_win=100).dropna()\n",
    "        idx = sv.index[sv.index < T - drop_last]\n",
    "        median_vol = sv.loc[idx, \"vol\"].median()\n",
    "        feats.loc[idx, \"slope_vol_reg\"] = np.where(\n",
    "            (sv.loc[idx, \"slope\"] > 0) & (sv.loc[idx, \"vol\"] < median_vol), 2, 0\n",
    "        )\n",
    "\n",
    "        # ... (other feature routines) ...\n",
    "\n",
    "        feats[\"true_regime\"] = true_regs\n",
    "        feats[\"inst\"] = inst\n",
    "        feats[\"time\"] = feats.index\n",
    "        all_rows.append(feats.reset_index(drop=True))\n",
    "\n",
    "    final_df = pd.concat(all_rows, ignore_index=True)\n",
    "    final_df.to_csv(output_csv, index=False)\n",
    "    print(f\"✅ Features written to: {output_csv}\")\n",
    "\n",
    "\n",
    "# ── Part B: Streaming warmup + efficient inference pipeline ─────────────────────────\n",
    "class StreamingRegimePredictor:\n",
    "    \"\"\"\n",
    "    Stream in price data for multiple instruments, warm up caches,\n",
    "    and emit a 1D numpy array of regime predictions (one per instrument)\n",
    "    once both price (100) and feature (20) caches are full.  Until then,\n",
    "    returns an array filled with -999.\n",
    "    \"\"\"\n",
    "    def __init__(self, checkpoint_name: str, features_csv: str):\n",
    "        # load frozen LSTM tagger\n",
    "        self.model, self.device = load_model(checkpoint_name)\n",
    "        # load static features (post-100 warm-up) for all instruments\n",
    "        df = pd.read_csv(features_csv)\n",
    "        feat_cols = [c for c in df.columns if c not in (\"inst\",\"time\",\"true_regime\")]\n",
    "        grouped = df.groupby(\"inst\")\n",
    "        self.static_feats = np.stack([grouped.get_group(i)[feat_cols].values\n",
    "                                      for i in sorted(grouped.groups)])\n",
    "        # cache placeholders\n",
    "        self.price_cache = None     # shape: (n_inst, 100)\n",
    "        self.feature_cache = None   # shape: (n_inst, 20, D)\n",
    "        self.n_inst, self.seq_len, self.D = self.static_feats.shape\n",
    "\n",
    "    def step(self, price_matrix: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Ingest the full historical price_matrix of shape (n_inst, T).\n",
    "        If T < 120, returns array([-999] * n_inst).\n",
    "        Once T >= 120, updates caches and emits latest predictions.\n",
    "        \"\"\"\n",
    "        if price_matrix.ndim != 2:\n",
    "            raise ValueError(\"price_matrix must be 2D: (n_inst, T)\")\n",
    "        n_inst, T = price_matrix.shape\n",
    "        if T < 120:\n",
    "            return np.full((n_inst,), -999, dtype=int)\n",
    "\n",
    "        # update price cache (last 100)\n",
    "        last_prices = price_matrix[:, -100:]\n",
    "        if self.price_cache is None:\n",
    "            self.price_cache = last_prices.copy()\n",
    "        else:\n",
    "            self.price_cache = np.roll(self.price_cache, -1, axis=1)\n",
    "            self.price_cache[:, -1] = last_prices[:, -1]\n",
    "\n",
    "        # compute which row of static_feats we need next\n",
    "        static_idx = T - 100 - 1\n",
    "        if static_idx < 0 or static_idx >= self.seq_len:\n",
    "            return np.full((n_inst,), -999, dtype=int)\n",
    "\n",
    "        new_feat = self.static_feats[:, static_idx, :]  # (n_inst, D)\n",
    "\n",
    "        # update feature cache (sliding window of length 20)\n",
    "        if self.feature_cache is None:\n",
    "            # initialize with the first 20 rows of static_feats\n",
    "            self.feature_cache = self.static_feats[:, :20, :].copy()\n",
    "        else:\n",
    "            self.feature_cache = np.roll(self.feature_cache, -1, axis=1)\n",
    "            self.feature_cache[:, -1, :] = new_feat\n",
    "\n",
    "        # run inference on *only* the latest timestep for each instrument\n",
    "        preds = np.zeros(self.n_inst, dtype=int)\n",
    "        for i in range(self.n_inst):\n",
    "            seq_preds     = predict_regimes(\n",
    "                self.model, self.device, self.feature_cache[i]\n",
    "            )            # returns shape (20,)\n",
    "            preds[i] = seq_preds[-1]  # grab the *last* regime in that sequence\n",
    "\n",
    "        return preds\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Simulate streaming prices\n",
    "    price_df = pd.read_csv(\"prices.txt\", sep=r\"\\s+\", header=None)\n",
    "    # price_df: shape (T, n_inst) -> transpose to (n_inst, T)\n",
    "    prices = price_df.values.T\n",
    "    pipeline = StreamingRegimePredictor(\n",
    "        checkpoint_name=\"bilstm_tagger.pth\",\n",
    "        features_csv=\"features_all_models4.csv\"\n",
    "    )\n",
    "    for t in range(1, prices.shape[1] + 1):\n",
    "        out = pipeline.step(prices[:, :t])\n",
    "        if (out == -999).all():\n",
    "            continue\n",
    "        print(f\"Predictions at t={t}:\", out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# make sure Python can find your AWP code\n",
    "sys.path.append(\"model_AWP\")\n",
    "\n",
    "from AWP_inference import load_model, predict_regimes\n",
    "from precision_labeller import plot_all_regimes_long\n",
    "\n",
    "# ─── helper to find contiguous segments ────────────────────────────────────────\n",
    "def get_segments(reg):\n",
    "    changes = np.flatnonzero(reg[1:] != reg[:-1])\n",
    "    starts  = np.concatenate(([0], changes + 1))\n",
    "    ends    = np.concatenate((changes, [len(reg)-1]))\n",
    "    return list(zip(starts, ends, reg[starts]))\n",
    "\n",
    "# ─── colour maps ───────────────────────────────────────────────────────────────\n",
    "true_cmap = ListedColormap([\"#ccffcc\",\"#f0f0f0\",\"#ffcccc\"])\n",
    "pred_cmap = ListedColormap([\"#66cc66\",\"#b0b0b0\",\"#ff6666\"])\n",
    "\n",
    "# ─── 1) load the model ─────────────────────────────────────────────────────────\n",
    "model, device = load_model(\"bilstm_tagger.pth\")\n",
    "\n",
    "# ─── 2) load the feature‐matrix and prices ────────────────────────────────────\n",
    "df = pd.read_csv(\"features_all_models4.csv\")\n",
    "# drop your first-100 warmups exactly as you did at training time:\n",
    "df = (\n",
    "    df\n",
    "    .groupby(\"inst\", group_keys=False)\n",
    "    .apply(lambda g: g.iloc[100:])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "price_df = pd.read_csv(\"prices.txt\", sep=r\"\\s+\", header=None)\n",
    "\n",
    "feat_cols = [c for c in df.columns if c not in (\"inst\",\"time\",\"true_regime\")]\n",
    "\n",
    "# ─── choose an instrument to demo ──────────────────────────────────────────────\n",
    "inst = 0\n",
    "sub  = df[df[\"inst\"]==inst].reset_index(drop=True)\n",
    "T    = len(sub)\n",
    "\n",
    "# ─── 3) get true regimes from the autolabeller ────────────────────────────────\n",
    "true_seq = plot_all_regimes_long(end_point=T, plot_graph=False, inst=inst)\n",
    "# this returns an array of length T\n",
    "\n",
    "# ─── 4) run your offline inference once ───────────────────────────────────────\n",
    "X_inst    = sub[feat_cols].values.astype(np.float32)  # shape (T, D)\n",
    "pred_seq  = predict_regimes(model, device, X_inst)    # shape (T,)\n",
    "\n",
    "# ─── 5) mask out any t<120 (still “warming up”) ──────────────────────────────\n",
    "warmup = 120\n",
    "masked_pred = np.full_like(pred_seq, fill_value=-1)  # or -999 if you prefer\n",
    "masked_pred[warmup:] = pred_seq[warmup:]\n",
    "\n",
    "# ─── 6) align prices (remember you dropped 100 warmups) ───────────────────────\n",
    "price = price_df.iloc[100:100+T, inst].values  # length T\n",
    "\n",
    "# ─── 7) now plot ──────────────────────────────────────────────────────────────\n",
    "fig, (ax_true, ax_pred) = plt.subplots(\n",
    "    2,1, sharex=True, figsize=(14,6),\n",
    "    gridspec_kw={\"height_ratios\":[1,1]}\n",
    ")\n",
    "\n",
    "# — True regimes panel —\n",
    "for s,e,lbl in get_segments(true_seq[warmup:]):\n",
    "    ax_true.axvspan(s+warmup, e+warmup, color=true_cmap(lbl), alpha=0.5, linewidth=0)\n",
    "ax_true.plot(price, \"k-\", linewidth=1.5, label=\"Price\")\n",
    "ax_true.set_title(f\"Inst {inst} — TRUE regimes (t≥{warmup})\")\n",
    "ax_true.set_ylabel(\"Price\")\n",
    "ax_true.legend(loc=\"upper left\")\n",
    "\n",
    "# — Predicted regimes panel —\n",
    "for s,e,lbl in get_segments(masked_pred[warmup:]):\n",
    "    ax_pred.axvspan(s+warmup, e+warmup, color=pred_cmap(lbl), alpha=0.5, linewidth=0)\n",
    "ax_pred.plot(price, \"k-\", linewidth=1.5, label=\"Price\")\n",
    "ax_pred.set_title(f\"Inst {inst} — PREDICTED regimes (t≥{warmup})\")\n",
    "ax_pred.set_xlabel(\"Time Step\")\n",
    "ax_pred.set_ylabel(\"Price\")\n",
    "ax_pred.legend(loc=\"upper left\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
