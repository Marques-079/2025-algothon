{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from precision_labeller import plot_all_regimes_long  # adjust import as needed\n",
    "\n",
    "def compute_ma_regimes(prices: pd.Series,\n",
    "                       short_w: int,\n",
    "                       long_w: int) -> np.ndarray:\n",
    "    \"\"\"Compute MA‐crossover regimes on log(prices) for one instrument.\"\"\"\n",
    "    logp     = np.log(prices)\n",
    "    ma_s     = logp.rolling(window=short_w, min_periods=1).mean()\n",
    "    ma_l     = logp.rolling(window=long_w,  min_periods=1).mean()\n",
    "    regs     = np.where(ma_l > ma_s, 0, 2)\n",
    "    return regs\n",
    "\n",
    "def grid_search_windows(price_file: str,\n",
    "                        short_range: range,\n",
    "                        long_range: range) -> pd.DataFrame:\n",
    "    # 1) load full price matrix\n",
    "    df = pd.read_csv(price_file, sep=r\"\\s+\", header=None)\n",
    "    n_inst = df.shape[1]\n",
    "    T      = df.shape[0]\n",
    "\n",
    "    # 2) get “true” regimes from your autolabeller (for one instrument at a time)\n",
    "    #    here we just test on inst=0; you can loop or average over multiple insts\n",
    "    true_regs = plot_all_regimes_long(end_point=T, plot_graph=False, inst=0)\n",
    "\n",
    "    rows = []\n",
    "    prices0 = df.iloc[:, 0]\n",
    "\n",
    "    # 3) loop over window pairs\n",
    "    for short_w in short_range:\n",
    "        for long_w in long_range:\n",
    "            if long_w <= short_w:\n",
    "                continue\n",
    "            pred_regs = compute_ma_regimes(prices0, short_w, long_w)\n",
    "            # trim to same length\n",
    "            pred_regs = pred_regs[: len(true_regs)]\n",
    "            #print(pred_regs)\n",
    "            acc = accuracy_score(true_regs, pred_regs)\n",
    "            rows.append({\"short_w\": short_w,\n",
    "                         \"long_w\":  long_w,\n",
    "                         \"accuracy\": acc})\n",
    "\n",
    "    results = pd.DataFrame(rows)\n",
    "    return results.sort_values(\"accuracy\", ascending=False)\n",
    "\n",
    "# ─── Example usage ───────────────────────────────────────────────\n",
    "shorts = range(5, 51, 5)    # try 5,10,…,50\n",
    "longs  = range(20, 201, 10) # try 20,30,…,200\n",
    "\n",
    "df_grid = grid_search_windows(\"prices.txt\", shorts, longs)\n",
    "print(df_grid.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from precision_labeller import plot_all_regimes_long  # your autolabeller\n",
    "\n",
    "def compute_ema_regimes(prices: pd.Series,\n",
    "                        short_span: int,\n",
    "                        long_span: int) -> np.ndarray:\n",
    "    \"\"\"Compute EMA‐crossover regimes on log(prices) for one instrument.\"\"\"\n",
    "    logp  = np.log(prices)\n",
    "    ema_s = logp.ewm(span=short_span, adjust=False).mean()\n",
    "    ema_l = logp.ewm(span=long_span,  adjust=False).mean()\n",
    "    regs  = np.where(ema_s > ema_l, 2, 0)  # bull=2 if short EMA > long EMA, else bear=0\n",
    "    return regs\n",
    "\n",
    "def grid_search_ema(price_file: str,\n",
    "                    short_range: range,\n",
    "                    long_range: range,\n",
    "                    inst: int = 0) -> pd.DataFrame:\n",
    "    # 1) load full price matrix\n",
    "    df = pd.read_csv(price_file, sep=r\"\\s+\", header=None)\n",
    "    T  = df.shape[0]\n",
    "\n",
    "    # 2) get “true” regimes from your autolabeller for instrument `inst`\n",
    "    true_regs = plot_all_regimes_long(end_point=T, plot_graph=False, inst=inst)\n",
    "\n",
    "    rows = []\n",
    "    prices0 = df.iloc[:, inst]\n",
    "\n",
    "    # 3) loop over span pairs\n",
    "    for short_span in short_range:\n",
    "        for long_span in long_range:\n",
    "            if long_span <= short_span:\n",
    "                continue\n",
    "            pred_regs = compute_ema_regimes(prices0, short_span, long_span)\n",
    "            pred_regs = pred_regs[: len(true_regs)]\n",
    "            acc = accuracy_score(true_regs, pred_regs)\n",
    "            rows.append({\n",
    "                \"short_span\": short_span,\n",
    "                \"long_span\":  long_span,\n",
    "                \"accuracy\":   acc\n",
    "            })\n",
    "\n",
    "    results = pd.DataFrame(rows)\n",
    "    return results.sort_values(\"accuracy\", ascending=False)\n",
    "\n",
    "# ─── Example usage ───────────────────────────────────────────────\n",
    "shorts = range(5, 51, 5)    # try spans 5,10,…,50\n",
    "longs  = range(20, 201, 10) # try spans 20,30,…,200\n",
    "\n",
    "df_ema = grid_search_ema(\"prices.txt\", shorts, longs, inst=0)\n",
    "print(df_ema.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_slope_vol(prices: pd.Series,\n",
    "                      slope_win: int,\n",
    "                      vol_win:   int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns a DataFrame [slope, vol] where:\n",
    "      - 'slope' is the OLS slope of log(price) over the past slope_win days,\n",
    "        computed only when we have exactly slope_win points.\n",
    "      - 'vol'   is the rolling std-dev of log-returns over vol_win days,\n",
    "        computed only when we have exactly vol_win days of returns.\n",
    "    \"\"\"\n",
    "    logp = np.log(prices)\n",
    "\n",
    "    # prebuild the design matrix for slope\n",
    "    t = np.arange(slope_win)\n",
    "    X = np.vstack([t, np.ones_like(t)]).T\n",
    "\n",
    "    def slope_of_window(y):\n",
    "        # y will always be length == slope_win\n",
    "        m, _ = np.linalg.lstsq(X, y, rcond=None)[0]\n",
    "        return m\n",
    "\n",
    "    # compute rolling slope, but only when we have slope_win points\n",
    "    slope = (\n",
    "        pd.Series(logp)\n",
    "          .rolling(window=slope_win, min_periods=slope_win)\n",
    "          .apply(slope_of_window, raw=True)\n",
    "    )\n",
    "\n",
    "    # compute rolling volatility of log-returns, only when vol_win returns exist\n",
    "    rtn = pd.Series(logp).diff()\n",
    "    vol = rtn.rolling(window=vol_win, min_periods=vol_win).std()\n",
    "\n",
    "    return pd.DataFrame({\"slope\": slope, \"vol\": vol})\n",
    "from sklearn.metrics import accuracy_score\n",
    "from precision_labeller import plot_all_regimes_long\n",
    "\n",
    "def grid_search_slope_vol(price_file: str,\n",
    "                          slope_range: range,\n",
    "                          vol_range:   range,\n",
    "                          inst: int = 0) -> pd.DataFrame:\n",
    "    df     = pd.read_csv(price_file, sep=r\"\\s+\", header=None)\n",
    "    T      = df.shape[0]\n",
    "    true   = plot_all_regimes_long(end_point=T, plot_graph=False, inst=inst)\n",
    "    prices = df.iloc[:, inst]   \n",
    "\n",
    "    rows = []\n",
    "    for sw in slope_range:\n",
    "        for vw in vol_range:\n",
    "            feats = compute_slope_vol(prices, sw, vw)\n",
    "            feats = feats.dropna()\n",
    "            \n",
    "            # ----- NEW: only keep indices that exist in `true` -----\n",
    "            idx = feats.index\n",
    "            idx = idx[idx < len(true)]\n",
    "            feats = feats.loc[idx]\n",
    "            \n",
    "            # now safe to align\n",
    "            true_trim = true[idx]\n",
    "\n",
    "            # simple bull/bear rule\n",
    "            thresh_vol = feats[\"vol\"].median()\n",
    "            regs = np.where(\n",
    "                (feats[\"slope\"] >  0) &\n",
    "                (feats[\"vol\"]   < thresh_vol),\n",
    "                2,  # bull\n",
    "                0   # bear\n",
    "            )\n",
    "\n",
    "            acc = accuracy_score(true_trim, regs)\n",
    "            rows.append({\"slope_win\": sw, \"vol_win\": vw, \"accuracy\": acc})\n",
    "\n",
    "    return pd.DataFrame(rows).sort_values(\"accuracy\", ascending=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ─── Example ────────────────────────────────────────────\n",
    "slopes = range(30, 101, 10)   # 30,40,…,100 days\n",
    "vols   = range(30, 101, 10)   # same for vol\n",
    "df_best = grid_search_slope_vol(\"prices.txt\", slopes, vols, inst=0)\n",
    "print(df_best.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from precision_labeller import plot_all_regimes_long  # your autolabeller\n",
    "\n",
    "def compute_macd_regimes(prices: pd.Series,\n",
    "                         short_span: int,\n",
    "                         long_span:  int,\n",
    "                         signal_span: int,\n",
    "                         drop_last:   int = 10) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute MACD crossover regimes on log-prices:\n",
    "      1) EMA_short  = EMA(logP, span=short_span)\n",
    "      2) EMA_long   = EMA(logP, span=long_span)\n",
    "      3) MACD_line  = EMA_short - EMA_long\n",
    "      4) Signal_line= EMA(MACD_line, span=signal_span)\n",
    "      5) regs = 2 if MACD_line > Signal_line else 0\n",
    "    Returns: array of length (len(prices) - drop_last), with initial NaNs dropped.\n",
    "    \"\"\"\n",
    "    logp       = np.log(prices)\n",
    "    ema_s      = logp.ewm(span=short_span, adjust=False).mean()\n",
    "    ema_l      = logp.ewm(span=long_span,  adjust=False).mean()\n",
    "    macd_line  = ema_s - ema_l\n",
    "    signal_ln  = macd_line.ewm(span=signal_span, adjust=False).mean()\n",
    "\n",
    "    regs_full = np.where(macd_line > signal_ln, 2, 0)\n",
    "    # drop last points to match labeller\n",
    "    regs_full = regs_full[: len(prices) - drop_last ]\n",
    "\n",
    "    # drop initial NaNs (from long_span or signal_span)\n",
    "    valid = ~np.isnan(regs_full)\n",
    "    return regs_full[valid], valid\n",
    "\n",
    "def grid_search_macd(price_file: str,\n",
    "                     short_range: range,\n",
    "                     long_range:  range,\n",
    "                     signal_range: range,\n",
    "                     inst: int = 0,\n",
    "                     drop_last: int = 10) -> pd.DataFrame:\n",
    "    # 1) load prices & get ground truth\n",
    "    df        = pd.read_csv(price_file, sep=r\"\\s+\", header=None)\n",
    "    T         = df.shape[0]\n",
    "    true_regs = plot_all_regimes_long(\n",
    "                    end_point=T,\n",
    "                    plot_graph=False,\n",
    "                    inst=inst,\n",
    "                \n",
    "                )\n",
    "    # trim ground truth to drop_last\n",
    "    true_regs = true_regs[: T - drop_last ]\n",
    "\n",
    "    prices0 = df.iloc[:, inst]\n",
    "    rows    = []\n",
    "\n",
    "    # 2) brute over all span combinations\n",
    "    for short_span in short_range:\n",
    "        for long_span in long_range:\n",
    "            if long_span <= short_span:\n",
    "                continue\n",
    "            for signal_span in signal_range:\n",
    "                # compute predicted regimes + mask for valid idx\n",
    "                pred_regs, valid = compute_macd_regimes(\n",
    "                                      prices0,\n",
    "                                      short_span,\n",
    "                                      long_span,\n",
    "                                      signal_span,\n",
    "                                      drop_last\n",
    "                                  )\n",
    "                # align to true\n",
    "                true_trim = true_regs[valid]\n",
    "\n",
    "                acc = accuracy_score(true_trim, pred_regs)\n",
    "                rows.append({\n",
    "                    \"short_span\":  short_span,\n",
    "                    \"long_span\":   long_span,\n",
    "                    \"signal_span\": signal_span,\n",
    "                    \"accuracy\":    acc\n",
    "                })\n",
    "\n",
    "    return pd.DataFrame(rows).sort_values(\"accuracy\", ascending=False)\n",
    "\n",
    "# ─── Example usage ────────────────────────────────────\n",
    "shorts  = range(5, 51, 5)    # 5,10,...,50\n",
    "longs   = range(20, 201, 10) # 20,30,...,200\n",
    "signals = range(5, 41, 5)    # 5,10,...,40\n",
    "\n",
    "df_macd = grid_search_macd(\"prices.txt\", shorts, longs, signals, inst=0, drop_last=10)\n",
    "print(df_macd.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from precision_labeller import plot_all_regimes_long  # your autolabeller\n",
    "\n",
    "def compute_kalman_regimes(prices: pd.Series,\n",
    "                           process_var:     float,\n",
    "                           measurement_var: float,\n",
    "                           drop_last:       int = 10) -> (np.ndarray, np.ndarray):\n",
    "    \"\"\"\n",
    "    1D Kalman filter trend on log-prices.\n",
    "    State x_t = trend estimate; measurement z_t = log-price.\n",
    "    process_var = Q; measurement_var = R.\n",
    "    Regime = 2 (bull) if logP_t > trend_t, else 0 (bear).\n",
    "    Trims last `drop_last` points and returns (regs, valid_mask).\n",
    "    \"\"\"\n",
    "    logp = np.log(prices).values\n",
    "    n    = len(logp)\n",
    "\n",
    "    x_est = np.zeros(n)  # filtered trend\n",
    "    P     = np.zeros(n)  # estimate variance\n",
    "\n",
    "    # initialize\n",
    "    x_est[0] = logp[0]\n",
    "    P[0]     = 1.0\n",
    "\n",
    "    for t in range(1, n):\n",
    "        # predict\n",
    "        x_pred = x_est[t-1]\n",
    "        P_pred = P[t-1] + process_var\n",
    "\n",
    "        # update\n",
    "        K         = P_pred / (P_pred + measurement_var)\n",
    "        x_est[t]  = x_pred + K * (logp[t] - x_pred)\n",
    "        P[t]      = (1 - K) * P_pred\n",
    "\n",
    "    # regime: bull if price above trend, else bear\n",
    "    regs_full = np.where(logp > x_est, 2, 0)\n",
    "\n",
    "    # trim tail to match labeller (T - drop_last)\n",
    "    N         = n - drop_last\n",
    "    regs_trim = regs_full[:N]\n",
    "\n",
    "    # no NaNs here, so all True\n",
    "    valid     = np.ones_like(regs_trim, dtype=bool)\n",
    "    return regs_trim, valid\n",
    "\n",
    "def grid_search_kalman(price_file:      str,\n",
    "                       process_vars:    list,\n",
    "                       measurement_vars: list,\n",
    "                       inst:            int = 0,\n",
    "                       drop_last:       int = 10) -> pd.DataFrame:\n",
    "    # 1) load prices & true regimes\n",
    "    df        = pd.read_csv(price_file, sep=r\"\\s+\", header=None)\n",
    "    T         = df.shape[0]\n",
    "    true_regs = plot_all_regimes_long(\n",
    "                    end_point=T,\n",
    "                    plot_graph=False,\n",
    "                    inst=inst,\n",
    "            \n",
    "                )[: T - drop_last]\n",
    "\n",
    "    prices0 = df.iloc[:, inst]\n",
    "    rows    = []\n",
    "\n",
    "    # 2) brute-force over Q × R\n",
    "    for Q in process_vars:\n",
    "        for R in measurement_vars:\n",
    "            pred_regs, valid = compute_kalman_regimes(\n",
    "                                  prices0, Q, R, drop_last\n",
    "                               )\n",
    "            true_trim = true_regs[valid]\n",
    "            acc       = accuracy_score(true_trim, pred_regs)\n",
    "            rows.append({\n",
    "                \"process_var (Q)\":     Q,\n",
    "                \"measurement_var (R)\": R,\n",
    "                \"accuracy\":            acc\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(rows).sort_values(\"accuracy\", ascending=False)\n",
    "\n",
    "# ─── Example usage ───────────────────────────────────────────────\n",
    "process_vars     = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1]\n",
    "measurement_vars = [1e-2, 1e-1, 1.0, 10.0]\n",
    "\n",
    "df_kalman = grid_search_kalman(\n",
    "    \"prices.txt\",\n",
    "    process_vars,\n",
    "    measurement_vars,\n",
    "    inst=0,\n",
    "    drop_last=10\n",
    ")\n",
    "print(df_kalman.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from precision_labeller import plot_all_regimes_long  # your autolabeller\n",
    "\n",
    "def compute_fib_regimes(prices: pd.Series,\n",
    "                        window:       int,\n",
    "                        lower_ratio:  float,\n",
    "                        upper_ratio:  float,\n",
    "                        drop_last:    int = 10):\n",
    "    \"\"\"\n",
    "    - window: look-back for high/low\n",
    "    - lower_ratio, upper_ratio: e.g. 0.382, 0.618 (must have lower_ratio < upper_ratio)\n",
    "    Regime = 2 (bull) if price > low + upper_ratio*(high-low)\n",
    "           = 0 (bear) if price < low + lower_ratio*(high-low)\n",
    "           = 1 (neutral) otherwise\n",
    "    \"\"\"\n",
    "    high = prices.rolling(window=window, min_periods=window).max()\n",
    "    low  = prices.rolling(window=window, min_periods=window).min()\n",
    "    range_ = high - low\n",
    "\n",
    "    # retracement levels\n",
    "    level_low  = low + lower_ratio * range_\n",
    "    level_high = low + upper_ratio * range_\n",
    "\n",
    "    regs_full = np.where(prices >  level_high, 2,\n",
    "                 np.where(prices <  level_low,  0, 1))\n",
    "\n",
    "    # trim tail to match autolabeller\n",
    "    N         = len(prices) - drop_last\n",
    "    regs_trim = regs_full[:N]\n",
    "    lvl_trim  = level_low[:N]  # just to get mask shape\n",
    "\n",
    "    valid = ~np.isnan(lvl_trim)\n",
    "    return regs_trim[valid], valid\n",
    "\n",
    "def grid_search_fib(price_file:     str,\n",
    "                    window_range:   range,\n",
    "                    ratio_range:    list,\n",
    "                    inst:           int = 0,\n",
    "                    drop_last:      int = 10) -> pd.DataFrame:\n",
    "    # 1) load data & ground truth\n",
    "    df        = pd.read_csv(price_file, sep=r\"\\s+\", header=None)\n",
    "    T         = df.shape[0]\n",
    "    true_regs = plot_all_regimes_long(\n",
    "                    end_point=T,\n",
    "                    plot_graph=False,\n",
    "                    inst=inst,\n",
    "   \n",
    "                )[: T - drop_last]\n",
    "\n",
    "    prices0 = df.iloc[:, inst]\n",
    "    rows    = []\n",
    "\n",
    "    # 2) grid over window × lower_ratio × upper_ratio\n",
    "    for w in window_range:\n",
    "        for lr in ratio_range:\n",
    "            for ur in ratio_range:\n",
    "                if ur <= lr:\n",
    "                    continue\n",
    "                pred, valid = compute_fib_regimes(\n",
    "                    prices=prices0,\n",
    "                    window=w,\n",
    "                    lower_ratio=lr,\n",
    "                    upper_ratio=ur,\n",
    "                    drop_last=drop_last\n",
    "                )\n",
    "                acc = accuracy_score(true_regs[valid], pred)\n",
    "                rows.append({\n",
    "                    \"window\":      w,\n",
    "                    \"lower_ratio\": lr,\n",
    "                    \"upper_ratio\": ur,\n",
    "                    \"accuracy\":    acc\n",
    "                })\n",
    "\n",
    "    return pd.DataFrame(rows).sort_values(\"accuracy\", ascending=False)\n",
    "\n",
    "# ─── Example usage ────────────────────────────────────────\n",
    "if __name__ == \"__main__\":\n",
    "    windows     = range(20, 121, 10)  # 20,30,...,120-day lookbacks\n",
    "    fib_levels  = [0.236, 0.382, 0.5, 0.618, 0.786]\n",
    "\n",
    "    df_fib = grid_search_fib(\n",
    "        \"prices.txt\",\n",
    "        windows,\n",
    "        fib_levels,\n",
    "        inst=0,\n",
    "        drop_last=10\n",
    "    )\n",
    "\n",
    "    # top 10\n",
    "    print(\"Top 10 Fibonacci grid-search results:\")\n",
    "    print(df_fib.head(10).to_string(index=False))\n",
    "\n",
    "    # best single combo\n",
    "    best = df_fib.iloc[0]\n",
    "    print(f\"\\nOptimal Fib params → window={best.window}, \"\n",
    "          f\"lower={best.lower_ratio}, upper={best.upper_ratio}, \"\n",
    "          f\"accuracy={best.accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from precision_labeller import plot_all_regimes_long  # your autolabeller\n",
    "\n",
    "def compute_psar_regimes(high: pd.Series,\n",
    "                        low: pd.Series,\n",
    "                        close: pd.Series,\n",
    "                        step: float,\n",
    "                        max_step: float,\n",
    "                        drop_last: int = 10):\n",
    "    \"\"\"\n",
    "    - step:      initial acceleration factor (e.g. 0.02)\n",
    "    - max_step:  maximum acceleration factor (e.g. 0.20)\n",
    "    PSAR algorithm on log-prices:\n",
    "      * trend up/down tracked via EP (extreme price) & AF (acceleration factor)\n",
    "      * PSAR_t = PSAR_{t-1} + AF * (EP - PSAR_{t-1})\n",
    "      * flip trend when price pierces PSAR\n",
    "    Regime = 2 if close > PSAR, else 0\n",
    "    \"\"\"\n",
    "    # initialize\n",
    "    n      = len(close)\n",
    "    psar   = np.zeros(n)\n",
    "    trend_up = True\n",
    "    af       = step\n",
    "    ep       = high.iloc[0]   # extreme point\n",
    "    psar[0]  = low.iloc[0] if trend_up else high.iloc[0]\n",
    "\n",
    "    # iterative PSAR\n",
    "    for t in range(1, n):\n",
    "        prev_psar = psar[t-1]\n",
    "        psar[t]   = prev_psar + af * (ep - prev_psar)\n",
    "\n",
    "        if trend_up:\n",
    "            # check for reversal\n",
    "            if low.iloc[t] < psar[t]:\n",
    "                trend_up = False\n",
    "                psar[t]  = ep\n",
    "                ep       = low.iloc[t]\n",
    "                af       = step\n",
    "            else:\n",
    "                # update EP & AF\n",
    "                if high.iloc[t] > ep:\n",
    "                    ep = high.iloc[t]\n",
    "                    af = min(af + step, max_step)\n",
    "        else:\n",
    "            if high.iloc[t] > psar[t]:\n",
    "                trend_up = True\n",
    "                psar[t]  = ep\n",
    "                ep       = high.iloc[t]\n",
    "                af       = step\n",
    "            else:\n",
    "                if low.iloc[t] < ep:\n",
    "                    ep = low.iloc[t]\n",
    "                    af = min(af + step, max_step)\n",
    "\n",
    "    # build regimes\n",
    "    regs_full = np.where(close.values > psar, 2, 0)\n",
    "\n",
    "    # trim tail to match labeller’s drop_last\n",
    "    N         = n - drop_last\n",
    "    regs_trim = regs_full[:N]\n",
    "    psar_trim = psar[:N]\n",
    "\n",
    "    # drop any NaN head (should be none after t=1)\n",
    "    valid = ~np.isnan(psar_trim)\n",
    "    return regs_trim[valid], valid\n",
    "\n",
    "def grid_search_psar(price_file: str,\n",
    "                     step_range:   list,\n",
    "                     max_range:    list,\n",
    "                     inst:         int = 0,\n",
    "                     drop_last:    int = 10) -> pd.DataFrame:\n",
    "    # 1) load price data & true regimes\n",
    "    df        = pd.read_csv(price_file, sep=r\"\\s+\", header=None)\n",
    "    T         = df.shape[0]\n",
    "    true_regs = plot_all_regimes_long(\n",
    "                    end_point=T,\n",
    "                    plot_graph=False,\n",
    "                    inst=inst,\n",
    "              \n",
    "                )[: T - drop_last]\n",
    "\n",
    "    # assume columns [inst]=Close, [inst+1]=High, [inst+2]=Low\n",
    "    close = df.iloc[:, inst]\n",
    "    high  = df.iloc[:, inst+1]\n",
    "    low   = df.iloc[:, inst+2]\n",
    "\n",
    "    rows = []\n",
    "    for step in step_range:\n",
    "        for max_step in max_range:\n",
    "            if max_step <= step:\n",
    "                continue\n",
    "            pred, valid = compute_psar_regimes(\n",
    "                high=high,\n",
    "                low=low,\n",
    "                close=close,\n",
    "                step=step,\n",
    "                max_step=max_step,\n",
    "                drop_last=drop_last\n",
    "            )\n",
    "            acc = accuracy_score(true_regs[valid], pred)\n",
    "            rows.append({\n",
    "                \"step\":     step,\n",
    "                \"max_step\": max_step,\n",
    "                \"accuracy\": acc\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(rows).sort_values(\"accuracy\", ascending=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # parameter ranges to try\n",
    "    step_range = [0.01, 0.02, 0.03, 0.04, 0.05]\n",
    "    max_range  = [0.1, 0.15, 0.2, 0.25, 0.3]\n",
    "\n",
    "    df_psar = grid_search_psar(\n",
    "        \"prices.txt\",\n",
    "        step_range,\n",
    "        max_range,\n",
    "        inst=0,\n",
    "        drop_last=10\n",
    "    )\n",
    "\n",
    "    # print top 10 and best combo\n",
    "    print(\"Top 10 Parabolic SAR parameter combos:\")\n",
    "    print(df_psar.head(10).to_string(index=False))\n",
    "\n",
    "    best = df_psar.iloc[0]\n",
    "    print(f\"\\nOptimal PSAR params → step={best.step}, \"\n",
    "          f\"max_step={best.max_step}, accuracy={best.accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from precision_labeller import plot_all_regimes_long  # your autolabeller\n",
    "\n",
    "def compute_zscore_regimes(prices: pd.Series,\n",
    "                           window: int,\n",
    "                           threshold: float,\n",
    "                           drop_last: int = 10):\n",
    "    \"\"\"\n",
    "    Compute Z-score based regimes:\n",
    "      - MA_t = rolling mean of prices over `window`\n",
    "      - SD_t = rolling std of prices over `window`\n",
    "      - Z_t  = (price_t - MA_t) / SD_t\n",
    "      - regs_t = 2 (bull) if Z_t > threshold\n",
    "               = 0 (bear) if Z_t < -threshold\n",
    "               = 1 (neutral) otherwise\n",
    "    Returns:\n",
    "      - regs_trim: 1D array of regimes length = len(prices)-drop_last minus NaNs\n",
    "      - valid:     boolean mask for non-NaN entries\n",
    "    \"\"\"\n",
    "    ma = prices.rolling(window=window, min_periods=window).mean()\n",
    "    sd = prices.rolling(window=window, min_periods=window).std()\n",
    "    z = (prices - ma) / sd\n",
    "\n",
    "    regs_full = np.where(z > threshold, 2,\n",
    "                 np.where(z < -threshold, 0, 1))\n",
    "\n",
    "    # trim tail to match labeller\n",
    "    N = len(prices) - drop_last\n",
    "    regs_trim = regs_full[:N]\n",
    "    z_trim = z[:N]\n",
    "\n",
    "    valid = ~np.isnan(z_trim)\n",
    "    return regs_trim[valid], valid\n",
    "\n",
    "def grid_search_zscore(price_file: str,\n",
    "                       window_range: range,\n",
    "                       threshold_range: list,\n",
    "                       inst: int = 0,\n",
    "                       drop_last: int = 10) -> pd.DataFrame:\n",
    "    # load price data and true regimes\n",
    "    df = pd.read_csv(price_file, sep=r\"\\s+\", header=None)\n",
    "    T  = df.shape[0]\n",
    "    true_regs = plot_all_regimes_long(\n",
    "        end_point=T,\n",
    "        plot_graph=False,\n",
    "        inst=inst,\n",
    "        \n",
    "    )[: T - drop_last]\n",
    "\n",
    "    prices0 = df.iloc[:, inst]\n",
    "    records = []\n",
    "\n",
    "    for w in window_range:\n",
    "        for th in threshold_range:\n",
    "            pred, valid = compute_zscore_regimes(\n",
    "                prices=prices0,\n",
    "                window=w,\n",
    "                threshold=th,\n",
    "                drop_last=drop_last\n",
    "            )\n",
    "            acc = accuracy_score(true_regs[valid], pred)\n",
    "            records.append({\n",
    "                \"window\": w,\n",
    "                \"threshold\": th,\n",
    "                \"accuracy\": acc\n",
    "            })\n",
    "\n",
    "    results = pd.DataFrame(records).sort_values(\"accuracy\", ascending=False)\n",
    "    return results\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    windows = range(10, 201, 10)          # e.g., 10,20,...,200\n",
    "    thresholds = [0.5, 1.0, 1.5, 2.0]      # z-score thresholds\n",
    "\n",
    "    df_z = grid_search_zscore(\n",
    "        \"prices.txt\",\n",
    "        windows,\n",
    "        thresholds,\n",
    "        inst=0,\n",
    "        drop_last=10\n",
    "    )\n",
    "    print(\"Top Z-score regime parameter combos:\")\n",
    "    print(df_z.head(10).to_string(index=False))\n",
    "\n",
    "    best = df_z.iloc[0]\n",
    "    print(f\"\\nOptimal Z-score params → window={best.window}, \"\n",
    "          f\"threshold={best.threshold}, accuracy={best.accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from precision_labeller import plot_all_regimes_long  # your autolabeller\n",
    "\n",
    "def compute_zscore_regimes(prices: pd.Series,\n",
    "                           window: int,\n",
    "                           threshold: float,\n",
    "                           drop_last: int = 10):\n",
    "    \"\"\"\n",
    "    Compute Z-score based regimes:\n",
    "      - MA_t = rolling mean of prices over `window`\n",
    "      - SD_t = rolling std of prices over `window`\n",
    "      - Z_t  = (price_t - MA_t) / SD_t\n",
    "      - regs_t = 2 (bull) if Z_t > threshold\n",
    "               = 0 (bear) if Z_t < -threshold\n",
    "               = 1 (neutral) otherwise (excluded from evaluation)\n",
    "    Returns:\n",
    "      - regs_trim: 1D array of regimes length = len(prices)-drop_last minus NaNs\n",
    "      - valid:     boolean mask for non-NaN entries\n",
    "    \"\"\"\n",
    "    ma = prices.rolling(window=window, min_periods=window).mean()\n",
    "    sd = prices.rolling(window=window, min_periods=window).std()\n",
    "    z = (prices - ma) / sd\n",
    "\n",
    "    regs_full = np.where(z > threshold, 2,\n",
    "                 np.where(z < -threshold, 0, 1))\n",
    "\n",
    "    N = len(prices) - drop_last\n",
    "    regs_trim = regs_full[:N]\n",
    "    z_trim = z[:N]\n",
    "\n",
    "    valid = ~np.isnan(z_trim)\n",
    "    return regs_trim[valid], valid\n",
    "\n",
    "def grid_search_zscore(price_file: str,\n",
    "                       window_range: range,\n",
    "                       threshold_range: list,\n",
    "                       inst: int = 0,\n",
    "                       drop_last: int = 10) -> pd.DataFrame:\n",
    "    # Load price data and true regimes\n",
    "    df = pd.read_csv(price_file, sep=r\"\\s+\", header=None)\n",
    "    T  = df.shape[0]\n",
    "    true_regs = plot_all_regimes_long(\n",
    "        end_point=T,\n",
    "        plot_graph=False,\n",
    "        inst=inst,\n",
    "    )[: T - drop_last]\n",
    "\n",
    "    prices0 = df.iloc[:, inst]\n",
    "    records = []\n",
    "\n",
    "    for w in window_range:\n",
    "        for th in threshold_range:\n",
    "            pred, valid = compute_zscore_regimes(\n",
    "                prices=prices0,\n",
    "                window=w,\n",
    "                threshold=th,\n",
    "                drop_last=drop_last\n",
    "            )\n",
    "\n",
    "            # Filter out neutral predictions (label=1)\n",
    "            pred_series = pd.Series(pred, index=np.arange(len(pred)))\n",
    "            true_series = pd.Series(true_regs[valid], index=np.arange(len(pred)))\n",
    "\n",
    "            mask = pred_series != 1\n",
    "            pred_bin = pred_series[mask]\n",
    "            true_bin = true_series[mask]\n",
    "\n",
    "            if len(pred_bin) == 0:\n",
    "                acc = np.nan  # skip if no bull/bear predictions\n",
    "            else:\n",
    "                acc = accuracy_score(true_bin, pred_bin)\n",
    "\n",
    "            records.append({\n",
    "                \"window\": w,\n",
    "                \"threshold\": th,\n",
    "                \"accuracy\": acc,\n",
    "                \"num_compared\": len(pred_bin)\n",
    "            })\n",
    "\n",
    "    results = pd.DataFrame(records).sort_values(\"accuracy\", ascending=False)\n",
    "    return results\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    windows = range(10, 201, 10)         # e.g., 10,20,...,200\n",
    "    thresholds = [0.5, 1.0, 1.5, 2.0]    # Z-score thresholds\n",
    "\n",
    "    df_z = grid_search_zscore(\n",
    "        \"prices.txt\",\n",
    "        windows,\n",
    "        thresholds,\n",
    "        inst=0,\n",
    "        drop_last=10\n",
    "    )\n",
    "\n",
    "    print(\"Top Z-score regime parameter combos (bull/bear only):\")\n",
    "    print(df_z.head(10).to_string(index=False))\n",
    "\n",
    "    best = df_z.iloc[0]\n",
    "    print(f\"\\nOptimal binary Z-score params → window={best.window}, \"\n",
    "          f\"threshold={best.threshold}, accuracy={best.accuracy:.4f}, \"\n",
    "          f\"compared on {int(best.num_compared)} samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from precision_labeller import plot_all_regimes_long  # or wherever you have it\n",
    "\n",
    "def compute_weighted_return_regimes(prices: pd.Series,\n",
    "                                    window: int,\n",
    "                                    power:  float,\n",
    "                                    drop_last: int = 10):\n",
    "    \"\"\"\n",
    "    - window: look-back in days\n",
    "    - power:  exponent on the linear weights (w_i = i**power)\n",
    "    Returns:\n",
    "      regs_trim, valid_mask\n",
    "    \"\"\"\n",
    "    # 1) 1-day returns\n",
    "    r = prices.pct_change()\n",
    "\n",
    "    # 2) build weights [1**p, 2**p, …, window**p] normalized\n",
    "    idx = np.arange(1, window+1)\n",
    "    w   = idx**power\n",
    "    w  /= w.sum()\n",
    "\n",
    "    # 3) rolling weighted sum (note: roll.apply hands you the last `window` values)\n",
    "    def wavg(arr):\n",
    "        # arr[-window:] corresponds to r_{t-window+1}…r_t\n",
    "        return np.dot(arr, w)\n",
    "\n",
    "    wr = r.rolling(window=window, min_periods=window).apply(wavg, raw=True)\n",
    "\n",
    "    # 4) regime: bull if >0, bear if <0, else neutral\n",
    "    regs_full = np.where(wr >  0, 2,\n",
    "                 np.where(wr <  0, 0, 1))\n",
    "\n",
    "    # 5) trim tail & head\n",
    "    N        = len(prices) - drop_last\n",
    "    regs_t   = regs_full[:N]\n",
    "    wr_t     = wr[:N]\n",
    "    valid    = ~np.isnan(wr_t)\n",
    "\n",
    "    return regs_t[valid], valid\n",
    "\n",
    "def grid_search_weighted_returns(price_file:    str,\n",
    "                                 window_range:  range,\n",
    "                                 power_range:   list,\n",
    "                                 inst:          int = 0,\n",
    "                                 drop_last:     int = 10) -> pd.DataFrame:\n",
    "    # 1) load data & true regimes\n",
    "    df        = pd.read_csv(price_file, sep=r\"\\s+\", header=None)\n",
    "    T         = df.shape[0]\n",
    "    true_regs = plot_all_regimes_long(\n",
    "                    end_point=T,\n",
    "                    plot_graph=False,\n",
    "                    inst=inst,\n",
    "                \n",
    "                )[: T - drop_last]\n",
    "\n",
    "    prices0 = df.iloc[:, inst]\n",
    "    rows    = []\n",
    "\n",
    "    # 2) grid over window × power\n",
    "    for w in window_range:\n",
    "        for p in power_range:\n",
    "            pred, valid = compute_weighted_return_regimes(\n",
    "                prices=prices0,\n",
    "                window=w,\n",
    "                power=p,\n",
    "                drop_last=drop_last\n",
    "            )\n",
    "            acc = accuracy_score(true_regs[valid], pred)\n",
    "            rows.append({\n",
    "                \"window\":   w,\n",
    "                \"power\":    p,\n",
    "                \"accuracy\": acc\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(rows).sort_values(\"accuracy\", ascending=False)\n",
    "\n",
    "# ─── Example usage ────────────────────────────────────────────\n",
    "if __name__ == \"__main__\":\n",
    "    windows = range(5, 51, 5)     # try 5,10,…,50-day lookbacks\n",
    "    powers  = [0.5, 1.0, 1.5, 2.0] # weight exponents\n",
    "\n",
    "    df_wr = grid_search_weighted_returns(\n",
    "        \"prices.txt\",\n",
    "        windows,\n",
    "        powers,\n",
    "        inst=0,\n",
    "        drop_last=10\n",
    "    )\n",
    "    print(\"Top weighted-returns regime parameter combos:\")\n",
    "    print(df_wr.head(10).to_string(index=False))\n",
    "\n",
    "    best = df_wr.iloc[0]\n",
    "    print(f\"\\nOptimal params → window={best.window}, power={best.power}, \"\n",
    "          f\"accuracy={best.accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "To save your Jupyter notebook as a PDF:\n",
    "\n",
    "1. In the Jupyter notebook interface, go to the menu bar and click on **File**.\n",
    "2. Select **Download as** > **PDF via LaTeX (.pdf)**.\n",
    "\n",
    "If you do not see the PDF option, you may need to install TeX (such as MiKTeX for Windows or MacTeX for Mac) and the `nbconvert` dependencies.  \n",
    "Alternatively, you can:\n",
    "\n",
    "- Go to **File** > **Print Preview**, then use your browser’s print dialog to \"Save as PDF\".\n",
    "\n",
    "This will save the PDF to your default downloads folder."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
