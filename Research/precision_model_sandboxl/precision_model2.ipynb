{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# ─── 1) Load & clean your features ────────────────────────────────────────────\n",
    "df = pd.read_csv(\"features_all_models4.csv\")\n",
    "df = (\n",
    "    df\n",
    "    .groupby(\"inst\", group_keys=False)\n",
    "    .apply(lambda g: g.iloc[100:])   # drop first 100 warm-ups per inst\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "X_all = df.drop([\"inst\",\"time\",\"true_regime\"], axis=1)\n",
    "y_all = df[\"true_regime\"]\n",
    "\n",
    "# ─── 2) Train one DecisionTree on everything ─────────────────────────────────\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "clf.fit(X_all, y_all)\n",
    "\n",
    "# ─── 3) Load raw prices ───────────────────────────────────────────────────────\n",
    "price_df = pd.read_csv(\"prices.txt\", sep=r\"\\s+\", header=None)\n",
    "\n",
    "# ─── 4) Helper to extract contiguous segments ─────────────────────────────────\n",
    "def get_segments(reg):\n",
    "    \"\"\"\n",
    "    Given a 1D array of regime labels, return a list of (start, end, label)\n",
    "    where each segment is contiguous and label ∈ {0,1,2}.\n",
    "    \"\"\"\n",
    "    changes = np.flatnonzero(reg[1:] != reg[:-1])\n",
    "    starts  = np.concatenate(([0], changes + 1))\n",
    "    ends    = np.concatenate((changes, [len(reg)-1]))\n",
    "    return list(zip(starts, ends, reg[starts]))\n",
    "\n",
    "# ─── 5) Prepare the 10×5 grid ────────────────────────────────────────────────\n",
    "n_rows, n_cols = 10, 5\n",
    "fig, axes     = plt.subplots(n_rows, n_cols, figsize=(20, 40), sharex=False)\n",
    "axes = axes.flatten()\n",
    "\n",
    "# colormaps for true vs. predicted\n",
    "true_cmap = ListedColormap([\"#ffcccc\",\"#f0f0f0\",\"#ccffcc\"])\n",
    "pred_cmap = ListedColormap([\"#ff6666\",\"#b0b0b0\",\"#66cc66\"])\n",
    "\n",
    "for inst in range(50):\n",
    "    ax = axes[inst]\n",
    "    # slice out inst i\n",
    "    mask   = (df[\"inst\"] == inst)\n",
    "    X_i    = X_all[mask]\n",
    "    true_i = y_all[mask].to_numpy()\n",
    "    pred_i = clf.predict(X_i)\n",
    "    T_i    = len(true_i)\n",
    "\n",
    "    # price series (dropping same 100 warmups)\n",
    "    price_i = price_df.iloc[100:100+T_i, inst].values\n",
    "\n",
    "    # 5a) plot true-regime background\n",
    "    for s, e, lbl in get_segments(true_i):\n",
    "        ax.axvspan(s, e, color=true_cmap(lbl), alpha=0.3, linewidth=0)\n",
    "\n",
    "    # 5b) plot predicted-regime overlay\n",
    "    for s, e, lbl in get_segments(pred_i):\n",
    "        ax.axvspan(s, e, color=pred_cmap(lbl), alpha=0.2, linewidth=0)\n",
    "\n",
    "    # 5c) plot the price on top\n",
    "    ax.plot(price_i, color=\"black\", linewidth=1, label=\"Price\")\n",
    "    ax.set_title(f\"Inst {inst}\")\n",
    "    ax.set_xlim(0, T_i)\n",
    "    ax.set_ylabel(\"Price\")\n",
    "\n",
    "    # only show legend on the very first plot\n",
    "    if inst == 0:\n",
    "        ax.legend(loc=\"upper right\")\n",
    "\n",
    "# clean up any empty subplots (in case 50 < n_rows*n_cols)\n",
    "for j in range(50, n_rows*n_cols):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# ── 1) Load & clean your features ─────────────────────────────────────────────\n",
    "df = pd.read_csv(\"features_all_models4.csv\")\n",
    "df = (\n",
    "    df\n",
    "    .groupby(\"inst\", group_keys=False)\n",
    "    .apply(lambda g: g.iloc[100:])   # drop first 100 warm-ups\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "X_all = df.drop([\"inst\",\"time\",\"true_regime\"], axis=1)\n",
    "y_all = df[\"true_regime\"]\n",
    "\n",
    "# ── 2) Train on first 500 samples ─────────────────────────────────────────────\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "clf.fit(X_all.iloc[:500], y_all.iloc[:500])\n",
    "print(f\"▶️ Trained on first 500 rows (of {len(y_all)})\\n\")\n",
    "\n",
    "# ── 3) Load raw prices ────────────────────────────────────────────────────────\n",
    "price_df = pd.read_csv(\"prices.txt\", sep=r\"\\s+\", header=None)\n",
    "\n",
    "# ── 4) Helper to find contiguous segments ─────────────────────────────────────\n",
    "def get_segments(reg):\n",
    "    changes = np.flatnonzero(reg[1:] != reg[:-1])\n",
    "    starts  = np.concatenate(([0], changes + 1))\n",
    "    ends    = np.concatenate((changes, [len(reg)-1]))\n",
    "    return list(zip(starts, ends, reg[starts]))\n",
    "\n",
    "# vivid colour palettes\n",
    "true_colors = ['#ff0000', '#808080', '#00ff00']  # red, grey, green\n",
    "pred_colors = ['#cc0000', '#444444', '#00cc00']  # darker red, dark grey, dark green\n",
    "\n",
    "# ── 5) Plot per instrument: separate “True” vs “Predicted” panels ────────────\n",
    "for inst in range(50):\n",
    "    mask   = (df[\"inst\"] == inst)\n",
    "    X_i    = X_all[mask]\n",
    "    true_i = y_all[mask].to_numpy()\n",
    "    pred_i = clf.predict(X_i)\n",
    "    T_i    = len(true_i)\n",
    "\n",
    "    price_i = price_df.iloc[100:100+T_i, inst].values\n",
    "\n",
    "    fig, (ax_true, ax_pred) = plt.subplots(\n",
    "        2, 1, sharex=True,\n",
    "        figsize=(12, 6),\n",
    "        gridspec_kw={'height_ratios':[1,1]}\n",
    "    )\n",
    "\n",
    "    # ─ True regimes panel ─────────────────────────────────────────────────────\n",
    "    for s, e, lbl in get_segments(true_i):\n",
    "        ax_true.axvspan(s, e, color=true_colors[lbl], alpha=0.5, linewidth=0)\n",
    "    ax_true.plot(price_i, color=\"black\", linewidth=1.5, label=\"Price\")\n",
    "    ax_true.set_title(f\"Instrument {inst} — True Regimes\")\n",
    "    ax_true.set_ylabel(\"Price\")\n",
    "    ax_true.legend(loc=\"upper right\")\n",
    "\n",
    "    # ─ Predicted regimes panel ─────────────────────────────────────────────────\n",
    "    for s, e, lbl in get_segments(pred_i):\n",
    "        ax_pred.axvspan(s, e, color=pred_colors[lbl], alpha=0.5, linewidth=0)\n",
    "    ax_pred.plot(price_i, color=\"black\", linewidth=1.5, label=\"Price\")\n",
    "    ax_pred.set_title(f\"Instrument {inst} — Predicted Regimes\")\n",
    "    ax_pred.set_xlabel(\"Time Step\")\n",
    "    ax_pred.set_ylabel(\"Price\")\n",
    "    ax_pred.legend(loc=\"upper right\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── 0) (Re)install a CPU-only PyTorch build to avoid NCCL errors ───────────────\n",
    "# !pip install --index-url https://download.pytorch.org/whl/cpu torch torchvision torchaudio --quiet\n",
    "\n",
    "# ── 1) Imports & inline plotting ───────────────────────────────────────────────\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# ── 2) Hyperparameters ────────────────────────────────────────────────────────\n",
    "SEQ_LEN     = 20\n",
    "BATCH_SIZE  = 64\n",
    "HIDDEN_SIZE = 64\n",
    "NUM_LAYERS  = 2\n",
    "DROPOUT     = 0.2\n",
    "LR          = 1e-3\n",
    "NUM_EPOCHS  = 20\n",
    "TEST_SIZE   = 0.3\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# ── 3) Dataset & Model ─────────────────────────────────────────────────────────\n",
    "class RegimeDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.from_numpy(X).float()\n",
    "        self.y = torch.from_numpy(y).long()\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "class RegimeLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes, dropout):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size=input_size,\n",
    "                            hidden_size=hidden_size,\n",
    "                            num_layers=num_layers,\n",
    "                            batch_first=True,\n",
    "                            dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)      # (batch, seq_len, hidden)\n",
    "        out = out[:, -1, :]        # last time-step\n",
    "        return self.fc(out)        # (batch, num_classes)\n",
    "\n",
    "# ── 4) Load & preprocess data ─────────────────────────────────────────────────\n",
    "# a) features\n",
    "df = pd.read_csv(\"features_all_models4.csv\")\n",
    "df = df.groupby(\"inst\", group_keys=False).apply(lambda g: g.iloc[100:]).reset_index(drop=True)\n",
    "\n",
    "# b) raw prices\n",
    "price_df = pd.read_csv(\"prices.txt\", sep=r\"\\s+\", header=None)\n",
    "\n",
    "# c) split out X, y and build sequences\n",
    "X_raw = df.drop([\"inst\",\"time\",\"true_regime\"], axis=1).values\n",
    "y_raw = df[\"true_regime\"].values\n",
    "NUM_CLASSES = int(y_raw.max())+1\n",
    "\n",
    "X_seqs, y_seqs, inst_map = [], [], []\n",
    "for inst in df[\"inst\"].unique():\n",
    "    mask = (df[\"inst\"]==inst).values\n",
    "    Xi, yi = X_raw[mask], y_raw[mask]\n",
    "    for t in range(SEQ_LEN, len(Xi)):\n",
    "        X_seqs.append(Xi[t-SEQ_LEN:t])\n",
    "        y_seqs.append(yi[t])\n",
    "        inst_map.append(inst)\n",
    "X_seqs   = np.stack(X_seqs)  # (N, SEQ_LEN, n_feat)\n",
    "y_seqs   = np.array(y_seqs)  # (N,)\n",
    "inst_map = np.array(inst_map)\n",
    "\n",
    "# ── 5) Train/val split ─────────────────────────────────────────────────────────\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_seqs, y_seqs,\n",
    "    test_size=TEST_SIZE,\n",
    "    stratify=y_seqs,\n",
    "    random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(RegimeDataset(X_train, y_train),\n",
    "                          batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader   = DataLoader(RegimeDataset(X_val, y_val),\n",
    "                          batch_size=BATCH_SIZE)\n",
    "\n",
    "# ── 6) Build & train the LSTM ─────────────────────────────────────────────────\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model  = RegimeLSTM(\n",
    "    input_size  = X_seqs.shape[2],\n",
    "    hidden_size = HIDDEN_SIZE,\n",
    "    num_layers  = NUM_LAYERS,\n",
    "    num_classes = NUM_CLASSES,\n",
    "    dropout     = DROPOUT\n",
    ").to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    model.train()\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "    for Xb, yb in train_loader:\n",
    "        Xb, yb = Xb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(Xb)\n",
    "        loss = criterion(out, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()*Xb.size(0)\n",
    "        preds = out.argmax(dim=1)\n",
    "        correct += (preds==yb).sum().item()\n",
    "        total   += yb.size(0)\n",
    "    print(f\"Epoch {epoch:02d}  Loss: {total_loss/total:.4f}  Acc: {correct/total:.4f}\")\n",
    "\n",
    "# ── 7) Inference & plotting per instrument ────────────────────────────────────\n",
    "def get_segments(reg):\n",
    "    changes = np.flatnonzero(reg[1:]!=reg[:-1])\n",
    "    starts  = np.concatenate(([0], changes+1))\n",
    "    ends    = np.concatenate((changes, [len(reg)-1]))\n",
    "    return list(zip(starts, ends, reg[starts]))\n",
    "\n",
    "true_cmap = ListedColormap([\"#ccffcc\",\"#f0f0f0\",\"#ffcccc\"])  # 2=green,1=grey,0=red\n",
    "pred_cmap = ListedColormap([\"#66cc66\",\"#b0b0b0\",\"#ff6666\"])\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for inst in sorted(np.unique(inst_map)):\n",
    "        mask   = inst_map==inst\n",
    "        Xi     = torch.from_numpy(X_seqs[mask]).float().to(device)\n",
    "        true_i = y_seqs[mask]\n",
    "        pred_i = model(Xi).argmax(dim=1).cpu().numpy()\n",
    "\n",
    "        # reconstruct full-length arrays (pad first SEQ_LEN steps)\n",
    "        Ni        = df[df[\"inst\"]==inst].shape[0]\n",
    "        price_i   = price_df.iloc[100:100+Ni, inst].values\n",
    "        true_full = np.concatenate([np.full(SEQ_LEN, np.nan), true_i])\n",
    "        pred_full = np.concatenate([np.full(SEQ_LEN, np.nan), pred_i])\n",
    "\n",
    "        # plot\n",
    "        fig, ax = plt.subplots(figsize=(12,4))\n",
    "        for s,e,lbl in get_segments(true_full[~np.isnan(true_full)].astype(int)):\n",
    "            ax.axvspan(s+SEQ_LEN, e+SEQ_LEN, color=true_cmap(lbl), alpha=0.3)\n",
    "        for s,e,lbl in get_segments(pred_full[~np.isnan(pred_full)].astype(int)):\n",
    "            ax.axvspan(s+SEQ_LEN, e+SEQ_LEN, color=pred_cmap(lbl), alpha=0.2)\n",
    "        ax.plot(price_i, color=\"black\", label=\"Price\")\n",
    "        ax.set_title(f\"Instrument {inst}\")\n",
    "        ax.set_xlabel(\"Time Step\")\n",
    "        ax.set_ylabel(\"Price\")\n",
    "        ax.legend()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ── 1) Hyperparameters ─────────────────────────────────────────────────────────\n",
    "SEQ_LEN     = 740\n",
    "TRAIN_LEN   = 500\n",
    "BATCH_SIZE  = 10\n",
    "HIDDEN_SIZE = 64\n",
    "NUM_LAYERS  = 2\n",
    "DROPOUT     = 0.2\n",
    "LR          = 1e-3\n",
    "NUM_EPOCHS  = 15\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# ── 2) Load & clean ─────────────────────────────────────────────────────────────\n",
    "df = pd.read_csv(\"features_all_models4.csv\")\n",
    "df = (\n",
    "    df\n",
    "    .groupby(\"inst\", group_keys=False)\n",
    "    .apply(lambda g: g.iloc[100:])   # drop first 100 warm-ups\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# recompute SEQ_LEN from the cleaned data:\n",
    "seq_lens = df.groupby(\"inst\").size()\n",
    "SEQ_LEN  = int(seq_lens.max())        # should be 640 in your case\n",
    "print(\"Detected sequence length per instrument:\", SEQ_LEN)\n",
    "\n",
    "# now build X and Y arrays with the correct shape\n",
    "n_inst    = df[\"inst\"].nunique()\n",
    "feat_cols = [c for c in df.columns if c not in (\"inst\",\"time\",\"true_regime\")]\n",
    "\n",
    "X = np.zeros((n_inst, SEQ_LEN, len(feat_cols)), dtype=np.float32)\n",
    "Y = np.zeros((n_inst, SEQ_LEN),               dtype=np.int64)\n",
    "\n",
    "for inst in range(n_inst):\n",
    "    sub = df[df[\"inst\"]==inst].reset_index(drop=True)\n",
    "    assert len(sub)==SEQ_LEN              # sanity check\n",
    "    X[inst,:,:] = sub[feat_cols].values\n",
    "    Y[inst,:]   = sub[\"true_regime\"].values\n",
    "\n",
    "NUM_TAGS = int(Y.max())+1\n",
    "\n",
    "\n",
    "# ── 3) Train/test split along time axis ────────────────────────────────────────\n",
    "X_train = torch.tensor(X[:, :TRAIN_LEN, :])\n",
    "Y_train = torch.tensor(Y[:, :TRAIN_LEN])\n",
    "X_full  = torch.tensor(X)      # for full‐sequence inference\n",
    "Y_full  = Y                   # numpy for plotting\n",
    "\n",
    "# ── 4) Dataset & DataLoader ───────────────────────────────────────────────────\n",
    "class SeqTagDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    def __len__(self):\n",
    "        return self.X.size(0)\n",
    "    def __getitem__(self, i):\n",
    "        return self.X[i], self.y[i]\n",
    "\n",
    "train_ds     = SeqTagDataset(X_train, Y_train)\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# ── 5) BiLSTM tagger ────────────────────────────────────────────────────────────\n",
    "class BiLSTMTagger(nn.Module):\n",
    "    def __init__(self, feat_dim, hidden_dim, num_layers, num_tags, dropout):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            feat_dim, hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_dim*2, num_tags)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)     # (B, T, 2*H)\n",
    "        return self.fc(out)       # (B, T, num_tags)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model  = BiLSTMTagger(\n",
    "    feat_dim   = X.shape[2],\n",
    "    hidden_dim = HIDDEN_SIZE,\n",
    "    num_layers = NUM_LAYERS,\n",
    "    num_tags   = NUM_TAGS,\n",
    "    dropout    = DROPOUT\n",
    ").to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "# ── 6) Train ───────────────────────────────────────────────────────────────────\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for feats, tags in train_loader:\n",
    "        feats, tags = feats.to(device), tags.to(device)\n",
    "        logits      = model(feats)              # (B, T, C)\n",
    "        loss        = criterion(\n",
    "            logits.view(-1, NUM_TAGS),         # (B*T, C)\n",
    "            tags.view(-1)                      # (B*T,)\n",
    "        )\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch:02d} — Avg Loss: {total_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# ── 7) Inference & two-panel plotting ──────────────────────────────────────────\n",
    "def get_segments(reg):\n",
    "    changes = np.flatnonzero(reg[1:] != reg[:-1])\n",
    "    starts  = np.concatenate(([0], changes+1))\n",
    "    ends    = np.concatenate((changes, [len(reg)-1]))\n",
    "    return list(zip(starts, ends, reg[starts]))\n",
    "\n",
    "true_cmap = ListedColormap([\"#ff0000\",\"#808080\",\"#00ff00\"])\n",
    "pred_cmap = ListedColormap([\"#cc0000\",\"#444444\",\"#00cc00\"])\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits_full = model(X_full.to(device))         # (50,740,C)\n",
    "    preds_full  = logits_full.argmax(dim=2).cpu().numpy()\n",
    "\n",
    "for inst in range(n_inst):\n",
    "    true_seq = Y_full[inst]\n",
    "    pred_seq = preds_full[inst]\n",
    "    price    = price_df.iloc[100:100+SEQ_LEN, inst].values\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(2,1,\n",
    "                                  sharex=True,\n",
    "                                  figsize=(12,6))\n",
    "\n",
    "    # TRUE regimes\n",
    "    for s,e,lbl in get_segments(true_seq):\n",
    "        ax1.axvspan(s, e, color=true_cmap(lbl), alpha=0.5, linewidth=0)\n",
    "    ax1.plot(price, 'k-', label='Price')\n",
    "    ax1.set_title(f\"Inst {inst} — TRUE regimes\")\n",
    "    ax1.legend(loc='upper right')\n",
    "\n",
    "    # PREDICTED regimes\n",
    "    for s,e,lbl in get_segments(pred_seq):\n",
    "        ax2.axvspan(s, e, color=pred_cmap(lbl), alpha=0.5, linewidth=0)\n",
    "    ax2.plot(price, 'k-', label='Price')\n",
    "    ax2.set_title(f\"Inst {inst} — PREDICTED regimes\")\n",
    "    ax2.legend(loc='upper right')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# ── 1) Hyperparameters ─────────────────────────────────────────────────────────\n",
    "TRAIN_LEN   = 400    # train on steps [0..399]\n",
    "BATCH_SIZE  = 10\n",
    "HIDDEN_SIZE = 64\n",
    "NUM_LAYERS  = 2\n",
    "DROPOUT     = 0.2\n",
    "LR          = 1e-3\n",
    "NUM_EPOCHS  = 15\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# ── 2) Load & clean ─────────────────────────────────────────────────────────────\n",
    "df = pd.read_csv(\"features_all_models4.csv\")\n",
    "df = (\n",
    "    df.groupby(\"inst\", group_keys=False)\n",
    "      .apply(lambda g: g.iloc[100:])   # drop first 100 warm-ups\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "price_df = pd.read_csv(\"prices.txt\", sep=r\"\\s+\", header=None)\n",
    "\n",
    "# detect sequence length per inst\n",
    "seq_lens = df.groupby(\"inst\").size()\n",
    "SEQ_LEN  = int(seq_lens.max())\n",
    "print(\"Sequence length per instrument:\", SEQ_LEN)\n",
    "\n",
    "# build X,Y arrays: (n_inst, SEQ_LEN, D) and (n_inst, SEQ_LEN)\n",
    "n_inst    = df[\"inst\"].nunique()\n",
    "feat_cols = [c for c in df.columns if c not in (\"inst\",\"time\",\"true_regime\")]\n",
    "\n",
    "X = np.zeros((n_inst, SEQ_LEN, len(feat_cols)), dtype=np.float32)\n",
    "Y = np.zeros((n_inst, SEQ_LEN),               dtype=np.int64)\n",
    "for inst in range(n_inst):\n",
    "    sub = df[df[\"inst\"]==inst].reset_index(drop=True)\n",
    "    X[inst] = sub[feat_cols].values\n",
    "    Y[inst] = sub[\"true_regime\"].values\n",
    "\n",
    "NUM_TAGS = int(Y.max()) + 1\n",
    "\n",
    "# ── 3) Split into train vs. test time windows ─────────────────────────────────\n",
    "X_train = torch.tensor(X[:, :TRAIN_LEN, :])\n",
    "Y_train = torch.tensor(Y[:, :TRAIN_LEN])\n",
    "X_test  = torch.tensor(X[:, TRAIN_LEN:, :])\n",
    "Y_test  = Y[:, TRAIN_LEN:]     # numpy for metrics & plotting\n",
    "LEN_TEST = SEQ_LEN - TRAIN_LEN\n",
    "\n",
    "# ── 4) Dataset & DataLoader ───────────────────────────────────────────────────\n",
    "class SeqTagDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X; self.y = y\n",
    "    def __len__(self):\n",
    "        return self.X.size(0)\n",
    "    def __getitem__(self, i):\n",
    "        return self.X[i], self.y[i]\n",
    "\n",
    "train_ds     = SeqTagDataset(X_train, Y_train)\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# ── 5) BiLSTM tagger ────────────────────────────────────────────────────────────\n",
    "class BiLSTMTagger(nn.Module):\n",
    "    def __init__(self, feat_dim, hidden_dim, num_layers, num_tags, dropout):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(feat_dim, hidden_dim,\n",
    "                            num_layers=num_layers,\n",
    "                            batch_first=True,\n",
    "                            bidirectional=True,\n",
    "                            dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_dim*2, num_tags)\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)     # (B, T, 2H)\n",
    "        return self.fc(out)       # (B, T, num_tags)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model  = BiLSTMTagger(\n",
    "    feat_dim   = X.shape[2],\n",
    "    hidden_dim = HIDDEN_SIZE,\n",
    "    num_layers = NUM_LAYERS,\n",
    "    num_tags   = NUM_TAGS,\n",
    "    dropout    = DROPOUT\n",
    ").to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "# ── 6) Train ───────────────────────────────────────────────────────────────────\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for feats, tags in train_loader:\n",
    "        feats, tags = feats.to(device), tags.to(device)\n",
    "        logits      = model(feats)\n",
    "        loss        = criterion(\n",
    "            logits.view(-1, NUM_TAGS),\n",
    "            tags.view(-1)\n",
    "        )\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch:02d} — Avg Loss: {total_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# ── 7) Inference on test window + metrics + plotting ──────────────────────────\n",
    "def get_segments(reg):\n",
    "    changes = np.flatnonzero(reg[1:] != reg[:-1])\n",
    "    starts  = np.concatenate(([0], changes+1))\n",
    "    ends    = np.concatenate((changes, [len(reg)-1]))\n",
    "    return list(zip(starts, ends, reg[starts]))\n",
    "\n",
    "true_cmap = ListedColormap([\"#ff0000\",\"#808080\",\"#00ff00\"])\n",
    "pred_cmap = ListedColormap([\"#cc0000\",\"#444444\",\"#00cc00\"])\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits_test = model(X_test.to(device))          # (50, LEN_TEST, C)\n",
    "    preds_test  = logits_test.argmax(dim=2).cpu().numpy()\n",
    "\n",
    "for inst in range(n_inst):\n",
    "    true_seq = Y_test[inst]\n",
    "    pred_seq = preds_test[inst]\n",
    "    price    = price_df.iloc[100+TRAIN_LEN:100+TRAIN_LEN+LEN_TEST, inst].values\n",
    "\n",
    "    # compute and print test accuracy\n",
    "    acc = (pred_seq == true_seq).mean()\n",
    "    print(f\"Inst {inst:02d} Test acc: {acc:.3f}\")\n",
    "\n",
    "    # two‐panel plot for test window only\n",
    "    fig, (ax1, ax2) = plt.subplots(2,1, sharex=True, figsize=(12,6))\n",
    "\n",
    "    # TRUE regimes\n",
    "    for s,e,lbl in get_segments(true_seq):\n",
    "        ax1.axvspan(s, e, color=true_cmap(lbl), alpha=0.5, linewidth=0)\n",
    "    ax1.plot(price, 'k-', label='Price')\n",
    "    ax1.set_title(f\"Inst {inst} — TRUE regimes (t={TRAIN_LEN}→end)\")\n",
    "    ax1.legend(loc='upper right')\n",
    "\n",
    "    # PREDICTED regimes\n",
    "    for s,e,lbl in get_segments(pred_seq):\n",
    "        ax2.axvspan(s, e, color=pred_cmap(lbl), alpha=0.5, linewidth=0)\n",
    "    ax2.plot(price, 'k-', label='Price')\n",
    "    ax2.set_title(f\"Inst {inst} — PREDICTED regimes (t={TRAIN_LEN}→end)\")\n",
    "    ax2.legend(loc='upper right')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
