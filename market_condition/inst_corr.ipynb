{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from scipy.stats import percentileofscore\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadPrices():\n",
    "    fn=\"../prices.txt\"\n",
    "    global nt, nInst\n",
    "    df=pd.read_csv(fn, sep=r'\\s+', header=None, index_col=None)\n",
    "    (nt,nInst) = df.shape\n",
    "    return nt, nInst, (df.values).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "(nt, nInst, prcAll) = loadPrices()\n",
    "prcTest = prcAll[:, :450]\n",
    "prcCheck = prcAll[:, 450:600]\n",
    "prcEval = prcAll[:, 600:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary: What Pearson Correlation on Log Returns Really Means\n",
    "# You're asking: \"When Asset A moves up or down more than usual, does Asset B also tend to move in the same direction, at the same time, and by how much?\"\n",
    "\n",
    "# By using log returns instead of prices: You're removing trend and scale, and looking purely at the rhythm of movement between two instruments.\n",
    "def comp_pearson(p_a, p_b):\n",
    "    log_returns_A = np.diff(np.log(p_a))\n",
    "    log_returns_B = np.diff(np.log(p_b))\n",
    "\n",
    "    # -------------------------------------\n",
    "    # Step 2: Compute Pearson Correlation\n",
    "    # -------------------------------------\n",
    "    pearson_np = np.corrcoef(log_returns_A, log_returns_B)[0, 1]\n",
    "\n",
    "    return pearson_np   \n",
    "\n",
    "\n",
    "def compute_correlation_matrix(prc_matrix, smooth=False, smooth_window=5):\n",
    "    \"\"\"\n",
    "    Computes a correlation matrix of log returns, optionally smoothed.\n",
    "\n",
    "    Parameters:\n",
    "        prc_matrix (ndarray): (instruments, time) closing price matrix\n",
    "        smooth (bool): Whether to smooth log returns before correlation\n",
    "        smooth_window (int): Window size for moving average smoothing\n",
    "\n",
    "    Returns:\n",
    "        corr_matrix (ndarray): (instruments, instruments) Pearson correlation matrix\n",
    "    \"\"\"\n",
    "    # Step 1: Compute log returns\n",
    "    log_prices = np.log(prc_matrix)\n",
    "    log_returns = np.diff(log_prices, axis=1)\n",
    "\n",
    "    # Step 2: Optional smoothing (moving average over time axis)\n",
    "    if smooth:\n",
    "        kernel = np.ones(smooth_window) / smooth_window\n",
    "        smoothed_returns = np.array([\n",
    "            np.convolve(r, kernel, mode='valid')\n",
    "            for r in log_returns\n",
    "        ])\n",
    "    else:\n",
    "        smoothed_returns = log_returns\n",
    "\n",
    "    # Step 3: Compute Pearson correlation matrix\n",
    "    corr_matrix = np.corrcoef(smoothed_returns)\n",
    "    return corr_matrix\n",
    "\n",
    "def plot_correlation_heatmap(corr_matrix, title=\"Correlation Matrix Heatmap\"):\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(\n",
    "        corr_matrix,\n",
    "        cmap='coolwarm',       # red = negative, blue = positive\n",
    "        vmin=-1, vmax=1,       # range of correlation values\n",
    "        center=0,\n",
    "        square=True,\n",
    "        cbar_kws={'shrink': .6},\n",
    "        xticklabels=False,\n",
    "        yticklabels=False\n",
    "    )\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def get_top_correlated_pairs(corr_matrix, top_n=5):\n",
    "    \"\"\"\n",
    "    Returns the top N most strongly positively correlated instrument index pairs\n",
    "    from a correlation matrix (excluding diagonal/self-correlations).\n",
    "\n",
    "    Parameters:\n",
    "        corr_matrix (ndarray): A symmetric NxN correlation matrix\n",
    "        top_n (int): Number of top pairs to return\n",
    "\n",
    "    Returns:\n",
    "        List of tuples: (instrument_i, instrument_j, correlation)\n",
    "    \"\"\"\n",
    "    # Get indices of upper triangle, excluding diagonal\n",
    "    n = corr_matrix.shape[0]\n",
    "    upper_tri_indices = np.triu_indices(n, k=1)\n",
    "\n",
    "    # Extract the upper triangle values and corresponding index pairs\n",
    "    corr_values = corr_matrix[upper_tri_indices]\n",
    "    index_pairs = list(zip(upper_tri_indices[0], upper_tri_indices[1]))\n",
    "\n",
    "    # Sort by correlation values descending\n",
    "    sorted_pairs = sorted(zip(index_pairs, corr_values), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Return top N\n",
    "    return [(i, j, round(val, 4)) for ((i, j), val) in sorted_pairs[:top_n]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking individual pearson corr  \n",
    "\n",
    "inst_a = 10\n",
    "inst_b = 11\n",
    "print(comp_pearson(prcTest[inst_a, :], prcTest[inst_b, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = compute_correlation_matrix(prcTest, True, 25)\n",
    "plot_correlation_heatmap(corr_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "top5 = get_top_correlated_pairs(corr_matrix, top_n=5)\n",
    "for i, j, val in top5:\n",
    "    print(f\"Instrument {i} & Instrument {j} → Correlation: {val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_top_correlated_pairs(prc_matrix, corr_matrix, top_n=5, use_returns=False, smooth=False, smooth_window=5):\n",
    "    \"\"\"\n",
    "    Plots the top N most correlated instrument pairs from a correlation matrix.\n",
    "\n",
    "    Parameters:\n",
    "        prc_matrix (ndarray): (instruments, time) closing price matrix\n",
    "        corr_matrix (ndarray): (instruments, instruments) correlation matrix\n",
    "        top_n (int): Number of top correlated pairs to plot\n",
    "        use_returns (bool): If True, plot log returns instead of prices\n",
    "        smooth (bool): Whether to apply moving average smoothing\n",
    "        smooth_window (int): Window size for smoothing (in days)\n",
    "    \"\"\"\n",
    "    # Step 1: Get top correlated index pairs\n",
    "    n = corr_matrix.shape[0]\n",
    "    upper = np.triu_indices(n, k=1)\n",
    "    corr_values = corr_matrix[upper]\n",
    "    index_pairs = list(zip(upper[0], upper[1]))\n",
    "    sorted_pairs = sorted(zip(index_pairs, corr_values), key=lambda x: x[1], reverse=True)\n",
    "    top_pairs = sorted_pairs[:top_n]\n",
    "\n",
    "    # Step 2: Compute returns or use prices\n",
    "    if use_returns:\n",
    "        log_prices = np.log(prc_matrix)\n",
    "        data = np.diff(log_prices, axis=1)\n",
    "        ylabel = \"Log Returns\"\n",
    "    else:\n",
    "        data = prc_matrix\n",
    "        ylabel = \"Price\"\n",
    "\n",
    "    # Step 3: Optional smoothing\n",
    "    if smooth:\n",
    "        # Apply moving average across time axis (axis=1)\n",
    "        kernel = np.ones(smooth_window) / smooth_window\n",
    "        data = np.array([\n",
    "            np.convolve(row, kernel, mode='valid')\n",
    "            for row in data\n",
    "        ])\n",
    "        xlabel = f\"Time (Days) [Smoothed, Window={smooth_window}]\"\n",
    "    else:\n",
    "        xlabel = \"Time (Days)\"\n",
    "\n",
    "    # Step 4: Plot each pair\n",
    "    for idx, ((i, j), corr_val) in enumerate(top_pairs, 1):\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        plt.plot(data[i], label=f\"Instrument {i}\", linewidth=2)\n",
    "        plt.plot(data[j], label=f\"Instrument {j}\", linewidth=2, linestyle='--')\n",
    "        plt.title(f\"Top {idx}: Instruments {i} & {j} (Correlation = {corr_val:.4f})\")\n",
    "        plt.xlabel(xlabel)\n",
    "        plt.ylabel(ylabel)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "plot_top_correlated_pairs(prcTest, corr_matrix, 5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_instrument_returns(prc_matrix, corr_matrix, target_idx):\n",
    "    \"\"\"\n",
    "    Predict the log returns of the target instrument as a weighted sum of\n",
    "    other instruments' log returns, weighted by their correlation with the target.\n",
    "\n",
    "    Parameters:\n",
    "        prc_matrix (ndarray): shape (num_instruments, num_days), closing prices\n",
    "        corr_matrix (ndarray): shape (num_instruments, num_instruments), correlation matrix of returns\n",
    "        target_idx (int): index of the instrument to predict\n",
    "\n",
    "    Returns:\n",
    "        predicted_returns (ndarray): predicted log returns for the target instrument, shape (num_days-1,)\n",
    "    \"\"\"\n",
    "    n = prc_matrix.shape[0]\n",
    "    assert corr_matrix.shape == (n, n), \"Correlation matrix shape mismatch\"\n",
    "\n",
    "    # Calculate log returns\n",
    "    log_prices = np.log(prc_matrix)\n",
    "    log_returns = np.diff(log_prices, axis=1)  # shape (n, num_days-1)\n",
    "\n",
    "    # Get weights from correlation matrix, zero self-correlation\n",
    "    weights = corr_matrix[target_idx].copy()\n",
    "    weights[target_idx] = 0\n",
    "\n",
    "    # Normalize weights by sum of absolute values to keep scale\n",
    "    sum_weights = np.sum(np.abs(weights))\n",
    "    if sum_weights != 0:\n",
    "        weights /= sum_weights\n",
    "\n",
    "    # Weighted sum of other instruments' returns to predict target returns\n",
    "    predicted_returns = weights @ log_returns  # shape (num_days-1,)\n",
    "\n",
    "    return predicted_returns\n",
    "\n",
    "\n",
    "def reconstruct_price_from_returns(start_price, returns):\n",
    "    \"\"\"\n",
    "    Reconstruct price series from starting price and log returns.\n",
    "\n",
    "    Parameters:\n",
    "        start_price (float): initial price before returns start\n",
    "        returns (ndarray): log returns array shape (num_days-1,)\n",
    "\n",
    "    Returns:\n",
    "        prices (ndarray): reconstructed price series shape (num_days,)\n",
    "    \"\"\"\n",
    "    cum_log_return = np.cumsum(returns)\n",
    "    prices = start_price * np.exp(cum_log_return)\n",
    "    prices = np.insert(prices, 0, start_price)  # include starting price\n",
    "    return prices\n",
    "\n",
    "\n",
    "def evaluate_predicted_returns(prc_matrix, predicted_returns, target_idx):\n",
    "    \"\"\"\n",
    "    Compare predicted returns with actual returns and compute metrics.\n",
    "\n",
    "    Parameters:\n",
    "        prc_matrix (ndarray): (num_instruments, num_days) price matrix\n",
    "        predicted_returns (ndarray): predicted log returns for target instrument, shape (num_days-1,)\n",
    "        target_idx (int): index of the instrument being predicted\n",
    "\n",
    "    Returns:\n",
    "        metrics (dict): mse, mae, r2 scores\n",
    "    \"\"\"\n",
    "    # Calculate actual log returns\n",
    "    log_prices = np.log(prc_matrix)\n",
    "    actual_returns = np.diff(log_prices[target_idx])\n",
    "\n",
    "    # Metrics\n",
    "    mse = mean_squared_error(actual_returns, predicted_returns)\n",
    "    mae = mean_absolute_error(actual_returns, predicted_returns)\n",
    "    r2 = r2_score(actual_returns, predicted_returns)\n",
    "\n",
    "    print(f\"Evaluation for Instrument {target_idx}:\")\n",
    "    print(f\"Mean Squared Error (MSE): {mse:.6f}\")\n",
    "    print(f\"Mean Absolute Error (MAE): {mae:.6f}\")\n",
    "    print(f\"R² Score: {r2:.4f}\")\n",
    "\n",
    "    # Plot actual vs predicted returns\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.plot(actual_returns, label='Actual Returns', alpha=0.7)\n",
    "    plt.plot(predicted_returns, label='Predicted Returns', alpha=0.7)\n",
    "    plt.title(f'Actual vs Predicted Returns for Instrument {target_idx}')\n",
    "    plt.xlabel('Days')\n",
    "    plt.ylabel('Log Return')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return {'mse': mse, 'mae': mae, 'r2': r2}\n",
    "r2 = list()\n",
    "\n",
    "data = prcCheck\n",
    "for target_idx in range(50):\n",
    "    predicted_ret = predict_instrument_returns(data, corr_matrix, target_idx)\n",
    "\n",
    "    # Reconstruct predicted prices starting from actual first price\n",
    "    predicted_prices = reconstruct_price_from_returns(data[target_idx, 0], predicted_ret)\n",
    "\n",
    "    plt.plot(data[target_idx], label=\"Actual Prices\")\n",
    "    plt.plot(predicted_prices, label=\"Predicted Prices from Correlation\")\n",
    "    plt.legend()\n",
    "    plt.title(f\"Actual vs Predicted Prices for Instrument {target_idx}\")\n",
    "    plt.show()\n",
    "    predicted_ret = predict_instrument_returns(data, corr_matrix, target_idx)\n",
    "    metrics = evaluate_predicted_returns(data, predicted_ret, target_idx)\n",
    "    r2.append(metrics['r2'])\n",
    "print(r2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_n_with_indices(arr, n=5):\n",
    "    arr = np.array(arr)\n",
    "    # Get indices of top n values\n",
    "    top_indices = np.argsort(arr)[-n:][::-1]\n",
    "    top_values = arr[top_indices]\n",
    "    return list(zip(top_indices, top_values))\n",
    "top5 = top_n_with_indices(r2, 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
