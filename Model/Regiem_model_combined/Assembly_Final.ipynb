{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regime_inference.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def _ols_slope(y: np.ndarray) -> float:\n",
    "    t = np.arange(len(y))\n",
    "    X = np.vstack([t, np.ones_like(t)]).T\n",
    "    m, _ = np.linalg.lstsq(X, y, rcond=None)[0]\n",
    "    return m\n",
    "\n",
    "\n",
    "def _slope_vol_reg(close: np.ndarray,\n",
    "                   idx:   int,\n",
    "                   slope_win: int = 30,\n",
    "                   vol_win:   int = 100\n",
    "                  ) -> float | int:\n",
    "    logp = np.log(close)\n",
    "\n",
    "    # 1) slope\n",
    "    slope_series = (\n",
    "        pd.Series(logp)\n",
    "          .rolling(slope_win, min_periods=slope_win)\n",
    "          .apply(_ols_slope, raw=True)\n",
    "    )\n",
    "    rtn        = pd.Series(logp).diff()\n",
    "    vol_series = rtn.rolling(vol_win, min_periods=1).std()\n",
    "\n",
    "    slope = slope_series.iloc[idx]\n",
    "    vol   = vol_series.iloc[idx]\n",
    "    if np.isnan(slope) or np.isnan(vol):\n",
    "        return np.nan\n",
    "\n",
    "    # 3) causal median of vol_series up to idx\n",
    "    median_vol = vol_series.iloc[: idx + 1].median()\n",
    "\n",
    "    return 2 if (slope > 0 and vol < median_vol) else 0\n",
    "\n",
    "\n",
    "\n",
    "def compute_regime_features_window(prices_window: np.ndarray) -> np.ndarray:\n",
    "\n",
    "    n_inst, win_len = prices_window.shape\n",
    "    idx = win_len - 1                   \n",
    "\n",
    "    out = np.full((n_inst, 9), np.nan)\n",
    "    sqrt_weights = np.arange(1, 46, dtype=float) ** 0.5\n",
    "    sqrt_weights /= sqrt_weights.sum()\n",
    "\n",
    "    for i in range(n_inst):\n",
    "        close = prices_window[i]\n",
    "        logp  = np.log(close)\n",
    "\n",
    "        # MA regime\n",
    "        ma_s = pd.Series(logp).rolling(5).mean().iloc[idx]\n",
    "        ma_l = pd.Series(logp).rolling(70).mean().iloc[idx]\n",
    "        ma_reg = 0 if ma_l > ma_s else 2\n",
    "\n",
    "        # EMA regime\n",
    "        ema_s = pd.Series(logp).ewm(span=5,  adjust=False).mean().iloc[idx]\n",
    "        ema_l = pd.Series(logp).ewm(span=50, adjust=False).mean().iloc[idx]\n",
    "        ema_reg = 2 if ema_s > ema_l else 0\n",
    "\n",
    "        # Slope/Vol regime\n",
    "        sv_reg = _slope_vol_reg(close, idx)\n",
    "\n",
    "        # MACD regime\n",
    "        macd_line = (\n",
    "            pd.Series(logp).ewm(50, adjust=False).mean()\n",
    "            - pd.Series(logp).ewm(90, adjust=False).mean()\n",
    "        )\n",
    "        signal_line = macd_line.ewm(span=40, adjust=False).mean()\n",
    "        macd_reg = 2 if macd_line.iloc[idx] > signal_line.iloc[idx] else 0\n",
    "\n",
    "        # Kalman trend regime\n",
    "        proc_var, meas_var = 0.01, 10.0\n",
    "        x_est = np.zeros(win_len)\n",
    "        P     = np.zeros(win_len)\n",
    "        x_est[0], P[0] = logp[0], 1.0\n",
    "        for t in range(1, win_len):\n",
    "            x_pred = x_est[t - 1]\n",
    "            P_pred = P[t - 1] + proc_var\n",
    "            K      = P_pred / (P_pred + meas_var)\n",
    "            x_est[t] = x_pred + K * (logp[t] - x_pred)\n",
    "            P[t]     = (1 - K) * P_pred\n",
    "        kalman_reg = 2 if logp[idx] > x_est[idx] else 0\n",
    "\n",
    "        # Fibonacci regime\n",
    "        if idx >= 50:\n",
    "            win50 = close[idx - 49 : idx + 1]\n",
    "            hi, lo = win50.max(), win50.min()\n",
    "            rng = hi - lo\n",
    "            upper, lower = lo + 0.786 * rng, lo + 0.618 * rng\n",
    "            fib_reg = 2 if close[idx] > upper else 0 if close[idx] < lower else 1\n",
    "        else:\n",
    "            fib_reg = np.nan\n",
    "\n",
    "        # PSAR regime\n",
    "        psar = np.empty(win_len)\n",
    "        trend_up, af, max_af = True, 0.01, 0.10\n",
    "        ep = close[0]\n",
    "        psar[0] = close[0]\n",
    "        for t in range(1, win_len):\n",
    "            psar[t] = psar[t - 1] + af * (ep - psar[t - 1])\n",
    "            if trend_up:\n",
    "                if close[t] < psar[t]:\n",
    "                    trend_up, psar[t], ep, af = False, ep, close[t], 0.01\n",
    "                elif close[t] > ep:\n",
    "                    ep, af = close[t], min(af + 0.01, max_af)\n",
    "            else:\n",
    "                if close[t] > psar[t]:\n",
    "                    trend_up, psar[t], ep, af = True, ep, close[t], 0.01\n",
    "                elif close[t] < ep:\n",
    "                    ep, af = close[t], min(af + 0.01, max_af)\n",
    "        psar_reg = 2 if close[idx] > psar[idx] else 0\n",
    "\n",
    "        # Z-score regime\n",
    "        ma90 = pd.Series(close).rolling(90).mean().iloc[idx]\n",
    "        sd90 = pd.Series(close).rolling(90).std().iloc[idx]\n",
    "        if np.isnan(ma90) or np.isnan(sd90):\n",
    "            zscore_reg = np.nan\n",
    "        else:\n",
    "            z = (close[idx] - ma90) / sd90\n",
    "            zscore_reg = 2 if z > 0.5 else 0 if z < -0.5 else 1\n",
    "\n",
    "        # Weighted-return regime\n",
    "        if idx >= 45:\n",
    "            r = pd.Series(close).pct_change().iloc[idx - 44 : idx + 1].values\n",
    "            wr = np.dot(r, sqrt_weights)\n",
    "            wret_reg = 2 if wr > 0 else 0 if wr < 0 else 1\n",
    "        else:\n",
    "            wret_reg = np.nan\n",
    "\n",
    "        out[i] = [\n",
    "            ma_reg, ema_reg, sv_reg, macd_reg, kalman_reg,\n",
    "            fib_reg, psar_reg, zscore_reg, wret_reg,\n",
    "        ]\n",
    "\n",
    "    return out\n",
    "\n",
    "def _extract_window(price_file: str,\n",
    "                    timestep: int,\n",
    "                    win_len: int = 100) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Slice the latest `win_len` bars (inclusive) ending at `timestep` from the\n",
    "    price file and transpose to (n_inst, win_len).\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(price_file, sep=r\"\\s+\", header=None)\n",
    "    n_rows, n_inst = df.shape\n",
    "\n",
    "    if not (0 <= timestep < n_rows):\n",
    "        raise ValueError(f\"timestep {timestep} out of range (0 … {n_rows-1})\")\n",
    "    if timestep < win_len - 1:\n",
    "        raise ValueError(\"Not enough history to build a 100-bar window.\")\n",
    "\n",
    "    slice_df = df.iloc[timestep - win_len + 1 : timestep + 1, :]\n",
    "    return slice_df.to_numpy().T            # (n_inst, win_len)\n",
    "\n",
    "\n",
    "def infer_from_file(price_file: str,\n",
    "                    timestep: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    High-level convenience wrapper:\n",
    "    1. read prices.txt\n",
    "    2. build the (50,100) window ending at `timestep`\n",
    "    3. run the regime-feature pipeline\n",
    "    \"\"\"\n",
    "    window = _extract_window(price_file, timestep, win_len=100)\n",
    "    #print(len(window[0]))\n",
    "    return compute_regime_features_window(window)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from precision_labeller import plot_all_regimes_long\n",
    "\n",
    "def build_feature_label_csv(price_file: str,\n",
    "                            N: int = 740,\n",
    "                            output_csv: str = \"features_labels.csv\"):\n",
    "    \"\"\"\n",
    "    Runs through timesteps 0..N-1 of prices.txt, builds the 9-regime features\n",
    "    for each instrument at each t, pulls in the true_autolabel, and saves\n",
    "    a long-form CSV indexed by instrument->time.\n",
    "    \"\"\"\n",
    "    # 1) load prices once\n",
    "    df_price = pd.read_csv(price_file, sep=r\"\\s+\", header=None)\n",
    "    n_rows, n_inst = df_price.shape\n",
    "    assert N <= n_rows, f\"N={N} exceeds available rows={n_rows}\"\n",
    "\n",
    "    # 2) precompute true regimes for each instrument\n",
    "    #    this returns an array length N for each inst\n",
    "    true_regs = {\n",
    "        inst: plot_all_regimes_long(end_point=N + 10, plot_graph=False, inst=inst)\n",
    "        for inst in range(n_inst)\n",
    "    }\n",
    "\n",
    "    # 3) iterate timesteps and call infer_from_file\n",
    "    records = []\n",
    "    for t in range(N):\n",
    "        try:\n",
    "            # infer_from_file expects timestep index in [0..]\n",
    "            feats_t = infer_from_file(price_file, timestep=t)\n",
    "            # feats_t is shape (n_inst, 9)\n",
    "        except ValueError:\n",
    "            # not enough history (t < 99), fill with NaNs\n",
    "            feats_t = np.full((n_inst, 9), np.nan)\n",
    "\n",
    "        for inst in range(n_inst):\n",
    "            row = {\n",
    "                \"inst\": inst,\n",
    "                \"time\": t,\n",
    "                \"ma\":          feats_t[inst, 0],\n",
    "                \"ema\":         feats_t[inst, 1],\n",
    "                \"slope_vol\":   feats_t[inst, 2],\n",
    "                \"macd\":        feats_t[inst, 3],\n",
    "                \"kalman\":      feats_t[inst, 4],\n",
    "                \"fib\":         feats_t[inst, 5],    \n",
    "                \"psar\":        feats_t[inst, 6],\n",
    "                \"zscore\":      feats_t[inst, 7],\n",
    "                \"wret\":        feats_t[inst, 8],\n",
    "                \"true_regime\": true_regs[inst][t]\n",
    "            }\n",
    "            records.append(row)\n",
    "\n",
    "    # 5) build DataFrame & save\n",
    "    df = pd.DataFrame.from_records(records)\n",
    "    df = df.sort_values([\"inst\", \"time\"]).reset_index(drop=True)\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"Wrote {len(df)} rows to {output_csv}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# ─── YOUR SAVED Bi-LSTM MODEL CLASS & LOADING ───────────────────────────────\n",
    "class RegimeBiLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes, dropout):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size   = input_size,\n",
    "            hidden_size  = hidden_size,\n",
    "            num_layers   = num_layers,\n",
    "            batch_first  = True,\n",
    "            dropout      = dropout,\n",
    "            bidirectional= True\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_size*2, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)      # (batch, seq_len, 2*hidden)\n",
    "        out    = out[:, -1, :]     # (batch, 2*hidden)\n",
    "        return self.fc(out)        # (batch, num_classes)\n",
    "\n",
    "\n",
    "# ─── CONFIGURATION ─────────────────────────────────────────────────────────\n",
    "PRICE_FILE   = \"prices.txt\"\n",
    "MODEL_PATH   = \"bilstm_self2.pth\"\n",
    "START        = 120\n",
    "END          = 750\n",
    "SEQ_LEN      = 20\n",
    "DEVICE       = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "FEAT_DIM     = 9\n",
    "HIDDEN_SIZE  = 64\n",
    "NUM_LAYERS   = 2\n",
    "NUM_CLASSES  = 3     # 0=bear,1=neutral,2=bull\n",
    "\n",
    "# ─── 1) LOAD MODEL ──────────────────────────────────────────────────────────\n",
    "print(f\"Loading model weights from {MODEL_PATH}...\")\n",
    "model = RegimeBiLSTM(FEAT_DIM, HIDDEN_SIZE, NUM_LAYERS, NUM_CLASSES, dropout=0.2)\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "model.to(DEVICE).eval()\n",
    "print(\"Model loaded. Starting inference run.\\n\")\n",
    "\n",
    "# ─── 2) LOAD PRICES ─────────────────────────────────────────────────────────\n",
    "prices_raw = pd.read_csv(PRICE_FILE, sep=r\"\\s+\", header=None).values\n",
    "T, N_INST  = prices_raw.shape\n",
    "print(f\"Price data dimensions: T={T}, instruments={N_INST}\\n\")\n",
    "\n",
    "# ─── 3) RUN INFERENCE STREAM ────────────────────────────────────────────────\n",
    "cache = []\n",
    "predictions = {inst: [] for inst in range(N_INST)}\n",
    "\n",
    "with torch.no_grad():\n",
    "    total = END - START + 1\n",
    "    for step, t in enumerate(range(START, END+1), 1):\n",
    "        feats_t = infer_from_file(PRICE_FILE, timestep=t)  # (N_INST,9)\n",
    "\n",
    "        cache.append(feats_t)\n",
    "        if len(cache) < SEQ_LEN:\n",
    "            print(f\"[{step}/{total}] warming cache {len(cache)}/{SEQ_LEN}\", end=\"\\r\")\n",
    "            continue\n",
    "        if len(cache) > SEQ_LEN:\n",
    "            cache.pop(0)\n",
    "\n",
    "        stacked = np.stack(cache, axis=0)               # (SEQ_LEN,N_INST,9)\n",
    "        seqs    = np.transpose(stacked, (1,0,2))        # (N_INST,SEQ_LEN,9)\n",
    "        Xb      = torch.from_numpy(seqs).float().to(DEVICE)\n",
    "\n",
    "        logits  = model(Xb)                             # (N_INST,3)\n",
    "        preds   = logits.argmax(dim=1).cpu().numpy()    # (N_INST,)\n",
    "\n",
    "        for inst in range(N_INST):\n",
    "            predictions[inst].append((t, int(preds[inst])))\n",
    "\n",
    "        print(f\"[{step}/{total}] t={t:4d}\", end=\"\\r\")\n",
    "    print(\"\\nInference complete!\\n\")\n",
    "\n",
    "\n",
    "# ─── 4) MINIMUM‐RUN SMOOTHER ─────────────────────────────────────────────────\n",
    "def smooth_min_run(raw: np.ndarray, L: int=4) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Enforce that you only flip to a new label if you see it run >= L times.\n",
    "    Otherwise you stay in the previous label.\n",
    "    \"\"\"\n",
    "    sm = np.empty_like(raw)\n",
    "    # helper to get raw runs\n",
    "    changes = np.flatnonzero(raw[:-1] != raw[1:])\n",
    "    starts  = np.concatenate(([0], changes+1))\n",
    "    ends    = np.concatenate((changes, [len(raw)-1]))\n",
    "\n",
    "    # first run: accept whatever it is\n",
    "    s0,e0 = starts[0], ends[0]\n",
    "    curr = raw[s0]\n",
    "    sm[s0:e0+1] = curr\n",
    "\n",
    "    # subsequent runs\n",
    "    for s,e in zip(starts[1:], ends[1:]):\n",
    "        lbl = raw[s]\n",
    "        run_len = e - s + 1\n",
    "        if lbl != curr and run_len >= L:\n",
    "            curr = lbl\n",
    "        sm[s:e+1] = curr\n",
    "\n",
    "    return sm\n",
    "\n",
    "#For plotting logic below -> May need to comment out\n",
    "def get_segments(label_seq):\n",
    "    \"\"\"Turn 1D label array into runs: [(start,end,label),…].\"\"\"\n",
    "    changes = np.flatnonzero(label_seq[:-1] != label_seq[1:])\n",
    "    starts  = np.concatenate(([0], changes+1))\n",
    "    ends    = np.concatenate((changes, [len(label_seq)-1]))\n",
    "    return list(zip(starts, ends, label_seq[starts]))\n",
    "\n",
    "\n",
    "true_cmap = ListedColormap([\"#ffcccc\",\"#f0f0f0\",\"#ccffcc\"])\n",
    "pred_cmap = ListedColormap([\"#ff6666\",\"#b0b0b0\",\"#66cc66\"])\n",
    "\n",
    "for inst in range(N_INST):\n",
    "    print(f\"Plotting inst {inst+1}/{N_INST}…\")\n",
    "    times, raw_labs = zip(*predictions[inst])\n",
    "    times      = np.array(times)\n",
    "    raw_labs   = np.array(raw_labs)\n",
    "    labs       = smooth_min_run(raw_labs, L=4)\n",
    "    price_slice = prices_raw[times, inst]\n",
    "    x = np.arange(len(times))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12,4))\n",
    "    for s,e,lbl in zip(*[ *zip(*get_segments(labs)) ]):\n",
    "        # bear=0, bull=2\n",
    "        if lbl==2:\n",
    "            ax.axvspan(x[s], x[e], color=pred_cmap.colors[2], alpha=0.3, lw=0)\n",
    "        elif lbl==0:\n",
    "            ax.axvspan(x[s], x[e], color=pred_cmap.colors[0], alpha=0.3, lw=0)\n",
    "\n",
    "    ax.plot(x, price_slice, \"k-\", label=\"Price\")\n",
    "    ax.set_title(f\"Instrument {inst:02d} — Smoothed preds {START}→{END}\")\n",
    "    ax.set_xlabel(\"Index in window\")\n",
    "    ax.set_ylabel(\"Price\")\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"All plots done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
