{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# ── 1) Hyperparameters ─────────────────────────────────────────────────────────\n",
    "TRAIN_LEN   = 400    # train on steps [0..399]\n",
    "BATCH_SIZE  = 10\n",
    "HIDDEN_SIZE = 64\n",
    "NUM_LAYERS  = 2\n",
    "DROPOUT     = 0.2\n",
    "LR          = 1e-3\n",
    "NUM_EPOCHS  = 15\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# ── 2) Load, clean & shift labels ───────────────────────────────────────────────\n",
    "df = pd.read_csv(\"features_all_models_FINAL.csv\")\n",
    "#  a) drop first 100 null‐warmups\n",
    "df = df.groupby(\"inst\", group_keys=False) \\\n",
    "       .apply(lambda g: g.iloc[100:]) \\\n",
    "       .reset_index(drop=True)\n",
    "#  b) shift labels *one day ahead* per instrument\n",
    "df[\"true_regime\"] = df.groupby(\"inst\")[\"true_regime\"].shift(-1)\n",
    "#  c) drop the last row of each instrument (now NaN label)\n",
    "df = df.dropna(subset=[\"true_regime\"]).reset_index(drop=True)\n",
    "df[\"true_regime\"] = df[\"true_regime\"].astype(int)\n",
    "\n",
    "price_df = pd.read_csv(\"prices.txt\", sep=r\"\\s+\", header=None)\n",
    "\n",
    "# ── 3) Determine sequence length & build arrays ────────────────────────────────\n",
    "seq_lens = df.groupby(\"inst\").size()\n",
    "SEQ_LEN  = int(seq_lens.max())\n",
    "print(\"Detected sequence length per instrument (post-shift):\", SEQ_LEN)\n",
    "\n",
    "n_inst    = df[\"inst\"].nunique()\n",
    "feat_cols = [c for c in df.columns if c not in (\"inst\",\"time\",\"true_regime\")]\n",
    "\n",
    "# initialize\n",
    "X = np.zeros((n_inst, SEQ_LEN, len(feat_cols)), dtype=np.float32)\n",
    "Y = np.zeros((n_inst, SEQ_LEN),               dtype=np.int64)\n",
    "\n",
    "# fill per-instrument\n",
    "for inst in range(n_inst):\n",
    "    sub = df[df[\"inst\"]==inst].reset_index(drop=True)\n",
    "    assert len(sub)==SEQ_LEN\n",
    "    X[inst] = sub[feat_cols].values\n",
    "    Y[inst] = sub[\"true_regime\"].values\n",
    "\n",
    "NUM_TAGS = int(Y.max()) + 1\n",
    "\n",
    "# ── 4) Split into train vs. test windows ──────────────────────────────────────\n",
    "X_train = torch.tensor(X[:, :TRAIN_LEN, :])\n",
    "Y_train = torch.tensor(Y[:, :TRAIN_LEN])\n",
    "X_test  = torch.tensor(X[:, TRAIN_LEN:, :])\n",
    "Y_test  = Y[:, TRAIN_LEN:]           # numpy for metrics & plotting\n",
    "LEN_TEST = SEQ_LEN - TRAIN_LEN\n",
    "\n",
    "# ── 5) Dataset & DataLoader ───────────────────────────────────────────────────\n",
    "class SeqTagDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X; self.y = y\n",
    "    def __len__(self):\n",
    "        return self.X.size(0)\n",
    "    def __getitem__(self, i):\n",
    "        return self.X[i], self.y[i]\n",
    "\n",
    "train_loader = DataLoader(SeqTagDataset(X_train, Y_train),\n",
    "                          batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# ── 6) BiLSTM tagger ───────────────────────────────────────────────────────────\n",
    "class BiLSTMTagger(nn.Module):\n",
    "    def __init__(self, feat_dim, hidden_dim, num_layers, num_tags, dropout):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(feat_dim, hidden_dim,\n",
    "                            num_layers=num_layers,\n",
    "                            batch_first=True,\n",
    "                            bidirectional=True,\n",
    "                            dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_dim*2, num_tags)\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)     # (B, T, 2H)\n",
    "        return self.fc(out)       # (B, T, num_tags)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model  = BiLSTMTagger(\n",
    "    feat_dim   = X.shape[2],\n",
    "    hidden_dim = HIDDEN_SIZE,\n",
    "    num_layers = NUM_LAYERS,\n",
    "    num_tags   = NUM_TAGS,\n",
    "    dropout    = DROPOUT\n",
    ").to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "# ── 7) Train ───────────────────────────────────────────────────────────────────\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for feats, tags in train_loader:\n",
    "        feats, tags = feats.to(device), tags.to(device)\n",
    "        logits      = model(feats)              # (B, T, C)\n",
    "        loss        = criterion(\n",
    "            logits.view(-1, NUM_TAGS),         # (B*T, C)\n",
    "            tags.view(-1)                      # (B*T,)\n",
    "        )\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch:02d} — Avg Loss: {total_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# ── 8) Inference + metrics + two‐panel plotting ───────────────────────────────\n",
    "def get_segments(reg):\n",
    "    changes = np.flatnonzero(reg[1:] != reg[:-1])\n",
    "    starts  = np.concatenate(([0], changes+1))\n",
    "    ends    = np.concatenate((changes, [len(reg)-1]))\n",
    "    return list(zip(starts, ends, reg[starts]))\n",
    "\n",
    "true_cmap = ListedColormap([\"#ff0000\",\"#808080\",\"#00ff00\"])\n",
    "pred_cmap = ListedColormap([\"#cc0000\",\"#444444\",\"#00cc00\"])\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits_test = model(X_test.to(device))      # (50, LEN_TEST, C)\n",
    "    preds_test  = logits_test.argmax(dim=2).cpu().numpy()\n",
    "\n",
    "for inst in range(n_inst):\n",
    "    true_seq = Y_test[inst]\n",
    "    pred_seq = preds_test[inst]\n",
    "    price    = price_df.iloc[100+TRAIN_LEN:100+TRAIN_LEN+LEN_TEST, inst].values\n",
    "\n",
    "    acc = (pred_seq == true_seq).mean()\n",
    "    print(f\"Inst {inst:02d} Test acc: {acc:.3f}\")\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(2,1, sharex=True, figsize=(12,6))\n",
    "\n",
    "    # TRUE regimes\n",
    "    for s,e,lbl in get_segments(true_seq):\n",
    "        ax1.axvspan(s, e, color=true_cmap(lbl), alpha=0.5, linewidth=0)\n",
    "    ax1.plot(price, 'k-', label='Price')\n",
    "    ax1.set_title(f\"Inst {inst} — TRUE regimes (t={TRAIN_LEN}→end)\")\n",
    "    ax1.legend(loc='upper right')\n",
    "\n",
    "    # PREDICTED regimes\n",
    "    for s,e,lbl in get_segments(pred_seq):\n",
    "        ax2.axvspan(s, e, color=pred_cmap(lbl), alpha=0.5, linewidth=0)\n",
    "    ax2.plot(price, 'k-', label='Price')\n",
    "    ax2.set_title(f\"Inst {inst} — PREDICTED regimes (t={TRAIN_LEN}→end)\")\n",
    "    ax2.legend(loc='upper right')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regime_inference.py  ——  ONLINE VERSION (Option B aligned)\n",
    "# ==========================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ───────────────────────── helpers ───────────────────────────────────────\n",
    "def _ols_slope(y: np.ndarray) -> float:\n",
    "    \"\"\"OLS slope of the vector y against a time index 0…len(y)-1.\"\"\"\n",
    "    t = np.arange(len(y))\n",
    "    X = np.vstack([t, np.ones_like(t)]).T\n",
    "    m, _ = np.linalg.lstsq(X, y, rcond=None)[0]\n",
    "    return m\n",
    "\n",
    "\n",
    "# ─── Slope/Vol regime  (★ causal 100-bar median, Option B) ───────────────\n",
    "def _slope_vol_reg(close: np.ndarray,\n",
    "                   idx:   int,\n",
    "                   slope_win: int = 30,\n",
    "                   vol_win:   int = 100) -> float | int:\n",
    "    \"\"\"\n",
    "    Classifies the bar *idx* in `close`:\n",
    "        2 = bull  (slope>0 and 1-day σ below rolling 100-bar median)\n",
    "        0 = bear\n",
    "        np.nan if any field NaN\n",
    "    The median rule is IDENTICAL to build_feature_matrix (Option B).\n",
    "    \"\"\"\n",
    "    logp = np.log(close)\n",
    "\n",
    "    # rolling slope\n",
    "    slope_series = (\n",
    "        pd.Series(logp)\n",
    "          .rolling(slope_win, min_periods=slope_win)\n",
    "          .apply(lambda arr: _ols_slope(arr), raw=True)\n",
    "    )\n",
    "\n",
    "    # rolling volatility (σ of log-returns over `vol_win`)\n",
    "    rtn         = pd.Series(logp).diff()\n",
    "    vol_series  = rtn.rolling(vol_win, min_periods=vol_win).std()\n",
    "\n",
    "    slope = slope_series.iloc[idx]\n",
    "    vol   = vol_series.iloc[idx]\n",
    "    if np.isnan(slope) or np.isnan(vol):\n",
    "        return np.nan\n",
    "\n",
    "    # causal 100-bar rolling median *of vol*\n",
    "    median_vol = (\n",
    "        vol_series\n",
    "          .rolling(window=100, min_periods=100)\n",
    "          .median()\n",
    "          .iloc[idx]\n",
    "    )\n",
    "\n",
    "    return 2 if (slope > 0 and vol < median_vol) else 0\n",
    "\n",
    "\n",
    "# ────────────────────── pipeline (no drop_last) ──────────────────────────\n",
    "def compute_regime_features_window(prices_window: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Input\n",
    "    -----\n",
    "    prices_window : np.ndarray, shape (n_inst, win_len)\n",
    "        Last `win_len` closes for each instrument (win_len ≥ 100).\n",
    "\n",
    "    Output\n",
    "    ------\n",
    "    np.ndarray, shape (n_inst, 9)\n",
    "        Columns ordered: [ma, ema, slope_vol, macd, kalman,\n",
    "                          fib, psar, zscore, wret]\n",
    "    \"\"\"\n",
    "    n_inst, win_len = prices_window.shape\n",
    "    idx = win_len - 1                     # evaluate at the newest bar\n",
    "\n",
    "    out = np.full((n_inst, 9), np.nan)\n",
    "    sqrt_w = np.arange(1, 46, dtype=float) ** 0.5\n",
    "    sqrt_w /= sqrt_w.sum()\n",
    "\n",
    "    for i in range(n_inst):\n",
    "        close = prices_window[i]\n",
    "        logp  = np.log(close)\n",
    "\n",
    "        # MA regime\n",
    "        ma_s  = pd.Series(logp).rolling(5).mean().iloc[idx]\n",
    "        ma_l  = pd.Series(logp).rolling(70).mean().iloc[idx]\n",
    "        ma_reg = 0 if ma_l > ma_s else 2\n",
    "\n",
    "        # EMA regime\n",
    "        ema_s = pd.Series(logp).ewm(span=5,  adjust=False).mean().iloc[idx]\n",
    "        ema_l = pd.Series(logp).ewm(span=50, adjust=False).mean().iloc[idx]\n",
    "        ema_reg = 2 if ema_s > ema_l else 0\n",
    "\n",
    "        # Slope/Vol regime\n",
    "        sv_reg = _slope_vol_reg(close, idx)\n",
    "\n",
    "        # MACD regime\n",
    "        macd_line = (\n",
    "            pd.Series(logp).ewm(50, adjust=False).mean()\n",
    "          - pd.Series(logp).ewm(90, adjust=False).mean()\n",
    "        )\n",
    "        signal_line = macd_line.ewm(span=40, adjust=False).mean()\n",
    "        macd_reg = 2 if macd_line.iloc[idx] > signal_line.iloc[idx] else 0\n",
    "\n",
    "        # Kalman trend regime\n",
    "        proc_var, meas_var = 0.01, 10.0\n",
    "        x_est = np.zeros(win_len)\n",
    "        P     = np.zeros(win_len)\n",
    "        x_est[0], P[0] = logp[0], 1.0\n",
    "        for t in range(1, win_len):\n",
    "            x_pred = x_est[t-1]\n",
    "            P_pred = P[t-1] + proc_var\n",
    "            K      = P_pred / (P_pred + meas_var)\n",
    "            x_est[t] = x_pred + K * (logp[t] - x_pred)\n",
    "            P[t]     = (1 - K) * P_pred\n",
    "        kalman_reg = 2 if logp[idx] > x_est[idx] else 0\n",
    "\n",
    "        # Fibonacci regime\n",
    "        if idx >= 50:\n",
    "            win50 = close[idx-49 : idx+1]\n",
    "            hi, lo = win50.max(), win50.min()\n",
    "            rng = hi - lo\n",
    "            upper, lower = lo + 0.786*rng, lo + 0.618*rng\n",
    "            fib_reg = 2 if close[idx] > upper else 0 if close[idx] < lower else 1\n",
    "        else:\n",
    "            fib_reg = np.nan\n",
    "\n",
    "        # PSAR regime\n",
    "        psar = np.empty(win_len)\n",
    "        trend_up, af, max_af = True, 0.01, 0.10\n",
    "        ep = close[0]\n",
    "        psar[0] = close[0]\n",
    "        for t in range(1, win_len):\n",
    "            psar[t] = psar[t-1] + af*(ep - psar[t-1])\n",
    "            if trend_up:\n",
    "                if close[t] < psar[t]:\n",
    "                    trend_up, psar[t], ep, af = False, ep, close[t], 0.01\n",
    "                elif close[t] > ep:\n",
    "                    ep, af = close[t], min(af+0.01, max_af)\n",
    "            else:\n",
    "                if close[t] > psar[t]:\n",
    "                    trend_up, psar[t], ep, af = True, ep, close[t], 0.01\n",
    "                elif close[t] < ep:\n",
    "                    ep, af = close[t], min(af+0.01, max_af)\n",
    "        psar_reg = 2 if close[idx] > psar[idx] else 0\n",
    "\n",
    "        # Z-score regime\n",
    "        ma90 = pd.Series(close).rolling(90).mean().iloc[idx]\n",
    "        sd90 = pd.Series(close).rolling(90).std().iloc[idx]\n",
    "        if np.isnan(ma90) or np.isnan(sd90):\n",
    "            zscore_reg = np.nan\n",
    "        else:\n",
    "            z = (close[idx] - ma90) / sd90\n",
    "            zscore_reg = 2 if z > 0.5 else 0 if z < -0.5 else 1\n",
    "\n",
    "        # Weighted-return regime\n",
    "        if idx >= 45:\n",
    "            r  = pd.Series(close).pct_change().iloc[idx-44 : idx+1].values\n",
    "            wr = np.dot(r, sqrt_w)\n",
    "            wret_reg = 2 if wr > 0 else 0 if wr < 0 else 1\n",
    "        else:\n",
    "            wret_reg = np.nan\n",
    "\n",
    "        out[i] = [\n",
    "            ma_reg, ema_reg, sv_reg, macd_reg, kalman_reg,\n",
    "            fib_reg, psar_reg, zscore_reg, wret_reg\n",
    "        ]\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# ──────────────────── I/O wrappers for prices.txt ───────────────────────\n",
    "def _extract_window(price_file: str,\n",
    "                    timestep: int,\n",
    "                    win_len: int = 100) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Extract the last `win_len` closes (inclusive) ending at `timestep`\n",
    "    and return an array with shape (n_inst, win_len).\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(price_file, sep=r\"\\s+\", header=None)\n",
    "    n_rows, _ = df.shape\n",
    "\n",
    "    if not (0 <= timestep < n_rows):\n",
    "        raise ValueError(f\"timestep {timestep} out of range (0 … {n_rows-1})\")\n",
    "    if timestep < win_len - 1:\n",
    "        raise ValueError(\"Not enough history to build a 100-bar window.\")\n",
    "\n",
    "    slice_df = df.iloc[timestep-win_len+1 : timestep+1, :]\n",
    "    return slice_df.to_numpy().T      # (n_inst, win_len)\n",
    "\n",
    "\n",
    "def infer_from_file(price_file: str,\n",
    "                    timestep:   int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Convenience:\n",
    "      • read prices.txt\n",
    "      • build a (n_inst, 100) window ending at `timestep`\n",
    "      • feed through compute_regime_features_window\n",
    "    \"\"\"\n",
    "    window = _extract_window(price_file, timestep, win_len=100)  # ← 100, not 102\n",
    "    return compute_regime_features_window(window)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "# 0)  Prepare training data  (X_train, Y_train already in your session)\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "X_flat = X_train.cpu().numpy().reshape(-1, X_train.shape[2])   # (N, 9)\n",
    "y_flat = Y_train.cpu().numpy().reshape(-1)                     # (N,)\n",
    "\n",
    "# Impute NaNs with column means (fits Option-B causal warm-up behaviour)\n",
    "col_means   = np.nanmean(X_flat, axis=0)\n",
    "X_flat_imp  = np.where(np.isnan(X_flat), col_means, X_flat)\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "# 1)  Fit proxy model\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "lr = LogisticRegression(\n",
    "    penalty=None,\n",
    "    solver='saga',\n",
    "    max_iter=20_000,\n",
    "    class_weight='balanced',\n",
    "    multi_class='ovr'\n",
    ")\n",
    "lr.fit(X_flat_imp, y_flat)\n",
    "print(\"✅ Logistic proxy trained on LSTM features\")\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "# 2)  Streaming inference\n",
    "# ─────────────────────────────────────────────────────────────────────  # after your Option-B update\n",
    "\n",
    "price_df = pd.read_csv(\"prices.txt\", sep=r\"\\s+\", header=None)\n",
    "n_rows, n_inst = price_df.shape\n",
    "WIN_LEN = 100          # ← must match infer_from_file()’s 100-bar window\n",
    "\n",
    "preds_all = np.zeros((n_inst, n_rows), dtype=int)\n",
    "\n",
    "for t in range(WIN_LEN-1, n_rows):\n",
    "    if (t - (WIN_LEN-1)) % 50 == 0 or t in (WIN_LEN-1, n_rows-1):\n",
    "        print(f\"Inferring at window end t={t}  (bar {t+1}/{n_rows})\")\n",
    "\n",
    "    feats_t = infer_from_file(\"prices.txt\", timestep=t)        # (n_inst, 9)\n",
    "    feats_t = np.where(np.isnan(feats_t), col_means, feats_t)  # impute\n",
    "\n",
    "    regs_t  = lr.predict(feats_t)\n",
    "    preds_all[:, t] = regs_t\n",
    "\n",
    "print(\"✅ Inference complete!\")\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "# 3)  Visualisation helper\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "def _segments(labels):\n",
    "    ch = np.flatnonzero(labels[:-1] != labels[1:])\n",
    "    starts = np.concatenate(([0], ch + 1))\n",
    "    ends   = np.concatenate((ch, [len(labels)-1]))\n",
    "    return zip(starts, ends, labels[starts])\n",
    "\n",
    "cmap = ListedColormap([\"#ffcccc\", \"#ccffcc\"])   # 0→bear, 2→bull\n",
    "\n",
    "for inst in range(n_inst):\n",
    "    price = price_df.iloc[:, inst].values\n",
    "    reg   = preds_all[inst]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 3))\n",
    "    for s, e, lbl in _segments(reg):\n",
    "        ax.axvspan(s, e, color=cmap(lbl // 2), alpha=0.35)\n",
    "    ax.plot(price, 'k-', lw=1)\n",
    "    ax.set_title(f\"Instrument {inst:02d}\")\n",
    "    ax.set_xlim(WIN_LEN-1, n_rows-1)\n",
    "    ax.set_xlabel(\"Timestep\")\n",
    "    ax.set_ylabel(\"Price\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "# 0)  (unchanged) Prepare training data  (X_train, Y_train in session)\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "X_flat = X_train.cpu().numpy().reshape(-1, X_train.shape[2])\n",
    "y_flat = Y_train.cpu().numpy().reshape(-1)\n",
    "\n",
    "col_means  = np.nanmean(X_flat, axis=0)\n",
    "X_flat_imp = np.where(np.isnan(X_flat), col_means, X_flat)\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "# 1)  (unchanged) Fit proxy model\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "lr = LogisticRegression(\n",
    "    penalty=None,\n",
    "    solver='saga',\n",
    "    max_iter=20_000,\n",
    "    class_weight='balanced',\n",
    "    multi_class='ovr'\n",
    ")\n",
    "lr.fit(X_flat_imp, y_flat)\n",
    "print(\"✅ Logistic proxy trained on LSTM features\")\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "# 2)  Streaming inference, but only print last LAST calls\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "price_df = pd.read_csv(\"prices.txt\", sep=r\"\\s+\", header=None)\n",
    "n_rows, n_inst = price_df.shape\n",
    "WIN_LEN = 100\n",
    "LAST    = 350\n",
    "\n",
    "preds_all = np.zeros((n_inst, n_rows), dtype=int)\n",
    "\n",
    "for t in range(WIN_LEN-1, n_rows):\n",
    "    feats_t = infer_from_file(\"prices.txt\", timestep=t)  \n",
    "    feats_t = np.where(np.isnan(feats_t), col_means, feats_t)\n",
    "    preds_all[:, t] = lr.predict(feats_t)\n",
    "\n",
    "    # only print the last LAST calls:\n",
    "    if t >= n_rows - LAST:\n",
    "        print(f\"Inferring at window end t={t}  (bar {t+1}/{n_rows})\")\n",
    "\n",
    "print(\"✅ Inference complete!\")\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "# 3)  Plot only the final LAST points\n",
    "# ─────────────────────────────────────────────────────────────────────\n",
    "def _segments(labels):\n",
    "    ch     = np.flatnonzero(labels[:-1] != labels[1:])\n",
    "    starts = np.concatenate(([0], ch + 1))\n",
    "    ends   = np.concatenate((ch, [len(labels)-1]))\n",
    "    return zip(starts, ends, labels[starts])\n",
    "\n",
    "cmap = ListedColormap([\"#ffcccc\", \"#ccffcc\"])   # 0→bear, 2→bull\n",
    "\n",
    "start = n_rows - LAST\n",
    "x_vals = np.arange(start, n_rows)  # for proper x-axis\n",
    "\n",
    "for inst in range(n_inst):\n",
    "    price_seg = price_df.iloc[start:, inst].values\n",
    "    reg_seg   = preds_all[inst, start:]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 3))\n",
    "    for s, e, lbl in _segments(reg_seg):\n",
    "        ax.axvspan(x_vals[s], x_vals[e], color=cmap(lbl // 2), alpha=0.35)\n",
    "    ax.plot(x_vals, price_seg, 'k-', lw=1)\n",
    "    ax.set_title(f\"Instrument {inst:02d} (last {LAST} bars)\")\n",
    "    ax.set_xlim(start, n_rows-1)\n",
    "    ax.set_xlabel(\"Timestep\")\n",
    "    ax.set_ylabel(\"Price\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# ── 1) Hyperparameters ─────────────────────────────────────────────────────────\n",
    "TRAIN_LEN   = 400\n",
    "BATCH_SIZE  = 10\n",
    "HIDDEN_SIZE = 128\n",
    "NUM_LAYERS  = 2\n",
    "NUM_HEADS   = 4      # added for transformer\n",
    "DROPOUT     = 0.2\n",
    "LR          = 1e-3\n",
    "NUM_EPOCHS  = 12\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# ── 2) Load, clean & shift labels ───────────────────────────────────────────────\n",
    "df = pd.read_csv(\"features_all_models_FINAL.csv\")\n",
    "df = df.groupby(\"inst\", group_keys=False).apply(lambda g: g.iloc[100:]).reset_index(drop=True)\n",
    "df[\"true_regime\"] = df.groupby(\"inst\")[\"true_regime\"].shift(-1)\n",
    "df = df.dropna(subset=[\"true_regime\"]).reset_index(drop=True)\n",
    "df[\"true_regime\"] = df[\"true_regime\"].astype(int)\n",
    "price_df = pd.read_csv(\"prices.txt\", sep=r\"\\s+\", header=None)\n",
    "\n",
    "# ── 3) Determine sequence length & build arrays ────────────────────────────────\n",
    "seq_lens = df.groupby(\"inst\").size()\n",
    "SEQ_LEN  = int(seq_lens.max())\n",
    "print(\"Detected sequence length per instrument (post-shift):\", SEQ_LEN)\n",
    "\n",
    "n_inst    = df[\"inst\"].nunique()\n",
    "feat_cols = [c for c in df.columns if c not in (\"inst\",\"time\",\"true_regime\")]\n",
    "\n",
    "X = np.zeros((n_inst, SEQ_LEN, len(feat_cols)), dtype=np.float32)\n",
    "Y = np.zeros((n_inst, SEQ_LEN),               dtype=np.int64)\n",
    "\n",
    "for inst in range(n_inst):\n",
    "    sub = df[df[\"inst\"]==inst].reset_index(drop=True)\n",
    "    X[inst] = sub[feat_cols].values\n",
    "    Y[inst] = sub[\"true_regime\"].values\n",
    "\n",
    "NUM_TAGS = int(Y.max()) + 1\n",
    "\n",
    "# ── 4) Split into train vs. test windows ──────────────────────────────────────\n",
    "X_train = torch.tensor(X[:, :TRAIN_LEN, :])\n",
    "Y_train = torch.tensor(Y[:, :TRAIN_LEN])\n",
    "X_test  = torch.tensor(X[:, TRAIN_LEN:, :])\n",
    "Y_test  = Y[:, TRAIN_LEN:]\n",
    "LEN_TEST = SEQ_LEN - TRAIN_LEN\n",
    "\n",
    "# ── 5) Dataset & DataLoader ───────────────────────────────────────────────────\n",
    "class SeqTagDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X; self.y = y\n",
    "    def __len__(self):\n",
    "        return self.X.size(0)\n",
    "    def __getitem__(self, i):\n",
    "        return self.X[i], self.y[i]\n",
    "\n",
    "train_loader = DataLoader(SeqTagDataset(X_train, Y_train),\n",
    "                          batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# ── Positional Encoding for Transformer ───────────────────────────────────────\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.2, max_len=1000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float()\n",
    "                             * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer(\"pe\", pe.unsqueeze(1))  # (max_len, 1, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (seq_len, batch, d_model)\n",
    "        x = x + self.pe[: x.size(0)]\n",
    "        return self.dropout(x)\n",
    "\n",
    "# ── 6) Transformer ──────────────────────────────────────────────────────\n",
    "class TransformerTagger(nn.Module):\n",
    "    def __init__(self, feat_dim, hidden_dim, num_layers, num_heads, dropout, num_tags, max_seq_len):\n",
    "        super().__init__()\n",
    "        self.input_proj = nn.Linear(feat_dim, hidden_dim)\n",
    "        self.pos_encoder = PositionalEncoding(hidden_dim, dropout, max_seq_len)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=hidden_dim,\n",
    "            nhead=num_heads,\n",
    "            dropout=dropout,\n",
    "            batch_first=False\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.fc = nn.Linear(hidden_dim, num_tags)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_proj(x)                     \n",
    "        x = x.permute(1, 0, 2)                      \n",
    "        x = self.pos_encoder(x)                     \n",
    "        out = self.transformer_encoder(x)           \n",
    "        out = out.permute(1, 0, 2)                  \n",
    "        return self.fc(out)                         \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = TransformerTagger(\n",
    "    feat_dim   = X.shape[2],\n",
    "    hidden_dim = HIDDEN_SIZE,\n",
    "    num_layers = NUM_LAYERS,\n",
    "    num_heads  = NUM_HEADS,\n",
    "    dropout    = DROPOUT,\n",
    "    num_tags   = NUM_TAGS,\n",
    "    max_seq_len= SEQ_LEN\n",
    ").to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "# ── 7) Train ───────────────────────────────────────────────────────────────────\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for feats, tags in train_loader:\n",
    "        feats, tags = feats.to(device), tags.to(device)\n",
    "        logits      = model(feats)                   \n",
    "        loss        = criterion(\n",
    "            logits.view(-1, NUM_TAGS),             \n",
    "            tags.view(-1)                          \n",
    "        )\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch:02d} — Avg Loss: {total_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# ── 8) Inference + metrics + two‐panel plotting ───────────────────────────────\n",
    "def get_segments(reg):\n",
    "    changes = np.flatnonzero(reg[1:] != reg[:-1])\n",
    "    starts  = np.concatenate(([0], changes+1))\n",
    "    ends    = np.concatenate((changes, [len(reg)-1]))\n",
    "    return list(zip(starts, ends, reg[starts]))\n",
    "\n",
    "true_cmap = ListedColormap([\"#ff0000\",\"#808080\",\"#00ff00\"])\n",
    "pred_cmap = ListedColormap([\"#cc0000\",\"#444444\",\"#00cc00\"])\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits_test = model(X_test.to(device))       # (n_inst, LEN_TEST, C)\n",
    "    preds_test  = logits_test.argmax(dim=2).cpu().numpy()\n",
    "\n",
    "for inst in range(n_inst):\n",
    "    true_seq = Y_test[inst]\n",
    "    pred_seq = preds_test[inst]\n",
    "    price    = price_df.iloc[100+TRAIN_LEN:100+TRAIN_LEN+LEN_TEST, inst].values\n",
    "\n",
    "    acc = (pred_seq == true_seq).mean()\n",
    "    print(f\"Inst {inst:02d} Test acc: {acc:.3f}\")\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(2,1, sharex=True, figsize=(12,6))\n",
    "    for s,e,lbl in get_segments(true_seq):\n",
    "        ax1.axvspan(s, e, color=true_cmap(lbl), alpha=0.5, linewidth=0)\n",
    "    ax1.plot(price, 'k-', label='Price')\n",
    "    ax1.set_title(f\"Inst {inst} — TRUE regimes (t={TRAIN_LEN}→end)\")\n",
    "    ax1.legend(loc='upper right')\n",
    "\n",
    "    for s,e,lbl in get_segments(pred_seq):\n",
    "        ax2.axvspan(s, e, color=pred_cmap(lbl), alpha=0.5, linewidth=0)\n",
    "    ax2.plot(price, 'k-', label='Price')\n",
    "    ax2.set_title(f\"Inst {inst} — PREDICTED regimes (t={TRAIN_LEN}→end)\")\n",
    "    ax2.legend(loc='upper right')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full Jupyter cell: k‐step‐ahead UniLSTM with no future leakage\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# ── Hyperparameters ────────────────────────────────────────────────────────────\n",
    "TRAIN_LEN   = 400\n",
    "BATCH_SIZE  = 10\n",
    "HIDDEN_SIZE = 64\n",
    "NUM_LAYERS  = 2\n",
    "DROPOUT     = 0.2\n",
    "LR          = 1e-3\n",
    "NUM_EPOCHS  = 15\n",
    "RANDOM_SEED = 42\n",
    "HORIZON     = 5    # predict regime 5 bars ahead\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# ── Load & prepare data ────────────────────────────────────────────────────────\n",
    "df = pd.read_csv(\"features_all_models_FINAL.csv\")\n",
    "# drop first 100 warmup\n",
    "df = df.groupby(\"inst\", group_keys=False).apply(lambda g: g.iloc[100:]).reset_index(drop=True)\n",
    "# shift labels by HORIZON ahead\n",
    "df[\"target_regime\"] = df.groupby(\"inst\")[\"true_regime\"].shift(-HORIZON)\n",
    "df = df.dropna(subset=[\"target_regime\"]).reset_index(drop=True)\n",
    "df[\"target_regime\"] = df[\"target_regime\"].astype(int)\n",
    "\n",
    "price_df = pd.read_csv(\"prices.txt\", sep=r\"\\s+\", header=None)\n",
    "\n",
    "# build sequences\n",
    "seq_lens = df.groupby(\"inst\").size()\n",
    "SEQ_LEN  = int(seq_lens.max())\n",
    "n_inst   = df[\"inst\"].nunique()\n",
    "feat_cols = [c for c in df.columns if c not in (\"inst\",\"time\",\"true_regime\",\"target_regime\")]\n",
    "\n",
    "X = np.zeros((n_inst, SEQ_LEN, len(feat_cols)), dtype=np.float32)\n",
    "Y = np.zeros((n_inst, SEQ_LEN),               dtype=np.int64)\n",
    "\n",
    "for inst in range(n_inst):\n",
    "    sub = df[df[\"inst\"]==inst].reset_index(drop=True)\n",
    "    X[inst] = sub[feat_cols].values\n",
    "    Y[inst] = sub[\"target_regime\"].values\n",
    "\n",
    "NUM_TAGS = int(Y.max()) + 1\n",
    "\n",
    "# ── Train/test split ───────────────────────────────────────────────────────────\n",
    "X_train = torch.tensor(X[:, :TRAIN_LEN, :])\n",
    "Y_train = torch.tensor(Y[:, :TRAIN_LEN])\n",
    "X_test  = torch.tensor(X[:, TRAIN_LEN:, :])\n",
    "Y_test  = Y[:, TRAIN_LEN:]     # numpy for plotting\n",
    "LEN_TEST = X_test.shape[1]\n",
    "\n",
    "# ── DataLoader ────────────────────────────────────────────────────────────────\n",
    "class SeqTagDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X, self.y = X, y\n",
    "    def __len__(self):\n",
    "        return self.X.size(0)\n",
    "    def __getitem__(self, i):\n",
    "        return self.X[i], self.y[i]\n",
    "\n",
    "train_loader = DataLoader(SeqTagDataset(X_train, Y_train),\n",
    "                          batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# ── Model definition ──────────────────────────────────────────────────────────\n",
    "class UniLSTMTagger(nn.Module):\n",
    "    def __init__(self, feat_dim, hidden_dim, num_layers, num_tags, dropout):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(feat_dim, hidden_dim,\n",
    "                            num_layers=num_layers,\n",
    "                            batch_first=True,\n",
    "                            bidirectional=False,\n",
    "                            dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_dim, num_tags)\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)   # (B, T, H)\n",
    "        return self.fc(out)     # (B, T, num_tags)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = UniLSTMTagger(len(feat_cols), HIDDEN_SIZE, NUM_LAYERS, NUM_TAGS, DROPOUT).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "# ── Training ─────────────────────────────────────────────────────────────────\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for feats, tags in train_loader:\n",
    "        feats, tags = feats.to(device), tags.to(device)\n",
    "        logits = model(feats)\n",
    "        loss = criterion(logits.view(-1, NUM_TAGS), tags.view(-1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch:02d} — Loss: {total_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# ── Inference & shift back ────────────────────────────────────────────────────\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits_test = model(X_test.to(device))                # (n_inst, LEN_TEST, C)\n",
    "    preds_test  = logits_test.argmax(dim=2).cpu().numpy()\n",
    "\n",
    "# drop last HORIZON preds to align with real-time\n",
    "preds_shift = preds_test[:, :-HORIZON]\n",
    "\n",
    "# ── Plotting ──────────────────────────────────────────────────────────────────\n",
    "def get_segments(reg):\n",
    "    changes = np.flatnonzero(reg[1:] != reg[:-1])\n",
    "    starts  = np.concatenate(([0], changes+1))\n",
    "    ends    = np.concatenate((changes, [len(reg)-1]))\n",
    "    return list(zip(starts, ends, reg[starts]))\n",
    "\n",
    "true_cmap = ListedColormap([\"#ff0000\",\"#00ff00\"])  # 0→bear, 2→bull\n",
    "pred_cmap = ListedColormap([\"#cc0000\",\"#00cc00\"])\n",
    "\n",
    "for inst in range(n_inst):\n",
    "    true_seq = Y_test[inst, HORIZON:]        # aligned true regimes at time t+H\n",
    "    pred_seq = preds_shift[inst]\n",
    "    price    = price_df.iloc[100+TRAIN_LEN+HORIZON : \n",
    "                              100+TRAIN_LEN+HORIZON+len(pred_seq), inst].values\n",
    "\n",
    "    acc = (pred_seq == true_seq).mean()\n",
    "    print(f\"Inst {inst:02d} Test acc (H={HORIZON}): {acc:.3f}\")\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(2,1, figsize=(12,6), sharex=True)\n",
    "    # TRUE\n",
    "    for s,e,lbl in get_segments(true_seq):\n",
    "        ax1.axvspan(s, e, color=true_cmap(lbl//2), alpha=0.4, linewidth=0)\n",
    "    ax1.plot(price, 'k-', label='Price'); ax1.set_title(f\"Inst {inst:02d} — TRUE regimes\")\n",
    "    # PREDICTED\n",
    "    for s,e,lbl in get_segments(pred_seq):\n",
    "        ax2.axvspan(s, e, color=pred_cmap(lbl//2), alpha=0.4, linewidth=0)\n",
    "    ax2.plot(price, 'k-', label='Price'); ax2.set_title(f\"Inst {inst:02d} — PREDICTED (H={HORIZON})\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
